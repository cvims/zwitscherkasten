
pytorch2.9.1+cu128:ˆÑ
ﬁ
mel_spectrogram
features.0.0.weight
features.0.0.weight_biasgetitemnode_Conv_437"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†Jú
	namespaceé: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.0: torchvision.ops.misc.Conv2dNormActivation/features.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJı
pkg.torch.onnx.class_hierarchy“['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jπ
pkg.torch.onnx.fx_nodeû%_native_batch_norm_legit_no_training : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d, %p_features_0_1_weight, %p_features_0_1_bias, %b_features_0_1_running_mean, %b_features_0_1_running_var, 0.01, 0.001), kwargs = {})Jt
pkg.torch.onnx.name_scopesV['', 'features', 'features.0', 'features.0.1', '_native_batch_norm_legit_no_training']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
Ë
getitem	hardswishn0"	HardSwishJÂ
	namespace◊: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.0: torchvision.ops.misc.Conv2dNormActivation/features.0.2: torch.nn.modules.activation.Hardswish/hardswish: aten.hardswish.defaultJŸ
pkg.torch.onnx.class_hierarchy∂['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jé
pkg.torch.onnx.fx_nodet%hardswish : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem,), kwargs = {})JY
pkg.torch.onnx.name_scopes;['', 'features', 'features.0', 'features.0.2', 'hardswish']Jí
pkg.torch.onnx.stack_traceÛFile "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
´
	hardswish
features.1.block.0.0.weight
 features.1.block.0.0.weight_bias	getitem_3node_Conv_439"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.1: torchvision.models.mobilenetv3.InvertedResidual/features.1.block: torch.nn.modules.container.Sequential/features.1.block.0: torchvision.ops.misc.Conv2dNormActivation/features.1.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_1: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J›
pkg.torch.onnx.fx_node¬%_native_batch_norm_legit_no_training_1 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_1, %p_features_1_block_0_1_weight, %p_features_1_block_0_1_bias, %b_features_1_block_0_1_running_mean, %b_features_1_block_0_1_running_var, 0.01, 0.001), kwargs = {})J©
pkg.torch.onnx.name_scopesä['', 'features', 'features.1', 'features.1.block', 'features.1.block.0', 'features.1.block.0.1', '_native_batch_norm_legit_no_training_1']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
‹
	getitem_3relu	node_relu"ReluJ⁄
	namespaceÃ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.1: torchvision.models.mobilenetv3.InvertedResidual/features.1.block: torch.nn.modules.container.Sequential/features.1.block.0: torchvision.ops.misc.Conv2dNormActivation/features.1.block.0.2: torch.nn.modules.activation.ReLU/relu: aten.relu.defaultJ´
pkg.torch.onnx.class_hierarchyà['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']JÜ
pkg.torch.onnx.fx_nodel%relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_3,), kwargs = {})JÜ
pkg.torch.onnx.name_scopesh['', 'features', 'features.1', 'features.1.block', 'features.1.block.0', 'features.1.block.0.2', 'relu']Jö	
pkg.torch.onnx.stack_trace˚File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
≥
relu
val_23mean	node_mean"
ReduceMean*
noop_with_empty_axes †*
keepdims†J„
	namespace’: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.1: torchvision.models.mobilenetv3.InvertedResidual/features.1.block: torch.nn.modules.container.Sequential/features.1.block.1: torchvision.ops.misc.SqueezeExcitation/features.1.block.1.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean: aten.mean.dimJÆ
pkg.torch.onnx.class_hierarchyã['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jå
pkg.torch.onnx.fx_noder%mean : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%relu, [-1, -2], True), kwargs = {})Jå
pkg.torch.onnx.name_scopesn['', 'features', 'features.1', 'features.1.block', 'features.1.block.1', 'features.1.block.1.avgpool', 'mean']J¢	
pkg.torch.onnx.stack_traceÉ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
≈
mean
features.1.block.1.fc1.weight
features.1.block.1.fc1.biasconv2d_2node_conv2d_2"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J€
	namespaceÕ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.1: torchvision.models.mobilenetv3.InvertedResidual/features.1.block: torch.nn.modules.container.Sequential/features.1.block.1: torchvision.ops.misc.SqueezeExcitation/features.1.block.1.fc1: torch.nn.modules.conv.Conv2d/conv2d_2: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J…
pkg.torch.onnx.fx_nodeÆ%conv2d_2 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean, %p_features_1_block_1_fc1_weight, %p_features_1_block_1_fc1_bias), kwargs = {})Jå
pkg.torch.onnx.name_scopesn['', 'features', 'features.1', 'features.1.block', 'features.1.block.1', 'features.1.block.1.fc1', 'conv2d_2']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Ô
conv2d_2relu_1node_relu_1"ReluJ‚
	namespace‘: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.1: torchvision.models.mobilenetv3.InvertedResidual/features.1.block: torch.nn.modules.container.Sequential/features.1.block.1: torchvision.ops.misc.SqueezeExcitation/features.1.block.1.activation: torch.nn.modules.activation.ReLU/relu_1: aten.relu.defaultJ®
pkg.torch.onnx.class_hierarchyÖ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Já
pkg.torch.onnx.fx_nodem%relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%conv2d_2,), kwargs = {})Jë
pkg.torch.onnx.name_scopess['', 'features', 'features.1', 'features.1.block', 'features.1.block.1', 'features.1.block.1.activation', 'relu_1']Jô	
pkg.torch.onnx.stack_trace˙File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
…
relu_1
features.1.block.1.fc2.weight
features.1.block.1.fc2.biasconv2d_3node_conv2d_3"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J€
	namespaceÕ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.1: torchvision.models.mobilenetv3.InvertedResidual/features.1.block: torch.nn.modules.container.Sequential/features.1.block.1: torchvision.ops.misc.SqueezeExcitation/features.1.block.1.fc2: torch.nn.modules.conv.Conv2d/conv2d_3: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÀ
pkg.torch.onnx.fx_node∞%conv2d_3 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_1, %p_features_1_block_1_fc2_weight, %p_features_1_block_1_fc2_bias), kwargs = {})Jå
pkg.torch.onnx.name_scopesn['', 'features', 'features.1', 'features.1.block', 'features.1.block.1', 'features.1.block.1.fc2', 'conv2d_3']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
ﬁ
conv2d_3hardsigmoidnode_hardsigmoid"HardSigmoid*
beta   ?†*
alpha´™*>†J˚
	namespaceÌ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.1: torchvision.models.mobilenetv3.InvertedResidual/features.1.block: torch.nn.modules.container.Sequential/features.1.block.1: torchvision.ops.misc.SqueezeExcitation/features.1.block.1.scale_activation: torch.nn.modules.activation.Hardsigmoid/hardsigmoid: aten.hardsigmoid.defaultJ∂
pkg.torch.onnx.class_hierarchyì['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Hardsigmoid', 'aten.hardsigmoid.default']Jì
pkg.torch.onnx.fx_nodey%hardsigmoid : [num_users=1] = call_function[target=torch.ops.aten.hardsigmoid.default](args = (%conv2d_3,), kwargs = {})Jú
pkg.torch.onnx.name_scopes~['', 'features', 'features.1', 'features.1.block', 'features.1.block.1', 'features.1.block.1.scale_activation', 'hardsigmoid']Jò	
pkg.torch.onnx.stack_trace˘File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 402, in forward
    return F.hardsigmoid(input, self.inplace)
ü
hardsigmoid
relumul_369node_mul_369"MulJ°
	namespaceì: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.1: torchvision.models.mobilenetv3.InvertedResidual/features.1.block: torch.nn.modules.container.Sequential/features.1.block.1: torchvision.ops.misc.SqueezeExcitation/mul_369: aten.mul.TensorJÇ
pkg.torch.onnx.class_hierarchyﬂ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jè
pkg.torch.onnx.fx_nodeu%mul_369 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%hardsigmoid, %relu), kwargs = {})Jq
pkg.torch.onnx.name_scopesS['', 'features', 'features.1', 'features.1.block', 'features.1.block.1', 'mul_369']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
©
mul_369
features.1.block.2.0.weight
 features.1.block.2.0.weight_bias	getitem_6node_Conv_441"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.1: torchvision.models.mobilenetv3.InvertedResidual/features.1.block: torch.nn.modules.container.Sequential/features.1.block.2: torchvision.ops.misc.Conv2dNormActivation/features.1.block.2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_2: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J›
pkg.torch.onnx.fx_node¬%_native_batch_norm_legit_no_training_2 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_4, %p_features_1_block_2_1_weight, %p_features_1_block_2_1_bias, %b_features_1_block_2_1_running_mean, %b_features_1_block_2_1_running_var, 0.01, 0.001), kwargs = {})J©
pkg.torch.onnx.name_scopesä['', 'features', 'features.1', 'features.1.block', 'features.1.block.2', 'features.1.block.2.1', '_native_batch_norm_legit_no_training_2']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
´
	getitem_6
features.2.block.0.0.weight
 features.2.block.0.0.weight_bias	getitem_9node_Conv_443"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.2: torchvision.models.mobilenetv3.InvertedResidual/features.2.block: torch.nn.modules.container.Sequential/features.2.block.0: torchvision.ops.misc.Conv2dNormActivation/features.2.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_3: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J›
pkg.torch.onnx.fx_node¬%_native_batch_norm_legit_no_training_3 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_5, %p_features_2_block_0_1_weight, %p_features_2_block_0_1_bias, %b_features_2_block_0_1_running_mean, %b_features_2_block_0_1_running_var, 0.01, 0.001), kwargs = {})J©
pkg.torch.onnx.name_scopesä['', 'features', 'features.2', 'features.2.block', 'features.2.block.0', 'features.2.block.0.1', '_native_batch_norm_legit_no_training_3']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
Ê
	getitem_9relu_2node_relu_2"ReluJ‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.2: torchvision.models.mobilenetv3.InvertedResidual/features.2.block: torch.nn.modules.container.Sequential/features.2.block.0: torchvision.ops.misc.Conv2dNormActivation/features.2.block.0.2: torch.nn.modules.activation.ReLU/relu_2: aten.relu.defaultJ´
pkg.torch.onnx.class_hierarchyà['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jà
pkg.torch.onnx.fx_noden%relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_9,), kwargs = {})Jà
pkg.torch.onnx.name_scopesj['', 'features', 'features.2', 'features.2.block', 'features.2.block.0', 'features.2.block.0.2', 'relu_2']Jö	
pkg.torch.onnx.stack_trace˚File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
©
relu_2
features.2.block.1.0.weight
 features.2.block.1.0.weight_bias
getitem_12node_Conv_445"Conv*
groupH†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.2: torchvision.models.mobilenetv3.InvertedResidual/features.2.block: torch.nn.modules.container.Sequential/features.2.block.1: torchvision.ops.misc.Conv2dNormActivation/features.2.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_4: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J›
pkg.torch.onnx.fx_node¬%_native_batch_norm_legit_no_training_4 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_6, %p_features_2_block_1_1_weight, %p_features_2_block_1_1_bias, %b_features_2_block_1_1_running_mean, %b_features_2_block_1_1_running_var, 0.01, 0.001), kwargs = {})J©
pkg.torch.onnx.name_scopesä['', 'features', 'features.2', 'features.2.block', 'features.2.block.1', 'features.2.block.1.1', '_native_batch_norm_legit_no_training_4']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
Ë

getitem_12relu_3node_relu_3"ReluJ‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.2: torchvision.models.mobilenetv3.InvertedResidual/features.2.block: torch.nn.modules.container.Sequential/features.2.block.1: torchvision.ops.misc.Conv2dNormActivation/features.2.block.1.2: torch.nn.modules.activation.ReLU/relu_3: aten.relu.defaultJ´
pkg.torch.onnx.class_hierarchyà['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jâ
pkg.torch.onnx.fx_nodeo%relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_12,), kwargs = {})Jà
pkg.torch.onnx.name_scopesj['', 'features', 'features.2', 'features.2.block', 'features.2.block.1', 'features.2.block.1.2', 'relu_3']Jö	
pkg.torch.onnx.stack_trace˚File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
©
relu_3
features.2.block.2.0.weight
 features.2.block.2.0.weight_bias
getitem_15node_Conv_447"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.2: torchvision.models.mobilenetv3.InvertedResidual/features.2.block: torch.nn.modules.container.Sequential/features.2.block.2: torchvision.ops.misc.Conv2dNormActivation/features.2.block.2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_5: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J›
pkg.torch.onnx.fx_node¬%_native_batch_norm_legit_no_training_5 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_7, %p_features_2_block_2_1_weight, %p_features_2_block_2_1_bias, %b_features_2_block_2_1_running_mean, %b_features_2_block_2_1_running_var, 0.01, 0.001), kwargs = {})J©
pkg.torch.onnx.name_scopesä['', 'features', 'features.2', 'features.2.block', 'features.2.block.2', 'features.2.block.2.1', '_native_batch_norm_legit_no_training_5']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
≠

getitem_15
features.3.block.0.0.weight
 features.3.block.0.0.weight_bias
getitem_18node_Conv_449"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.3: torchvision.models.mobilenetv3.InvertedResidual/features.3.block: torch.nn.modules.container.Sequential/features.3.block.0: torchvision.ops.misc.Conv2dNormActivation/features.3.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_6: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J›
pkg.torch.onnx.fx_node¬%_native_batch_norm_legit_no_training_6 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_8, %p_features_3_block_0_1_weight, %p_features_3_block_0_1_bias, %b_features_3_block_0_1_running_mean, %b_features_3_block_0_1_running_var, 0.01, 0.001), kwargs = {})J©
pkg.torch.onnx.name_scopesä['', 'features', 'features.3', 'features.3.block', 'features.3.block.0', 'features.3.block.0.1', '_native_batch_norm_legit_no_training_6']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
Ë

getitem_18relu_4node_relu_4"ReluJ‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.3: torchvision.models.mobilenetv3.InvertedResidual/features.3.block: torch.nn.modules.container.Sequential/features.3.block.0: torchvision.ops.misc.Conv2dNormActivation/features.3.block.0.2: torch.nn.modules.activation.ReLU/relu_4: aten.relu.defaultJ´
pkg.torch.onnx.class_hierarchyà['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jâ
pkg.torch.onnx.fx_nodeo%relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_18,), kwargs = {})Jà
pkg.torch.onnx.name_scopesj['', 'features', 'features.3', 'features.3.block', 'features.3.block.0', 'features.3.block.0.2', 'relu_4']Jö	
pkg.torch.onnx.stack_trace˚File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
©
relu_4
features.3.block.1.0.weight
 features.3.block.1.0.weight_bias
getitem_21node_Conv_451"Conv*
groupX†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.3: torchvision.models.mobilenetv3.InvertedResidual/features.3.block: torch.nn.modules.container.Sequential/features.3.block.1: torchvision.ops.misc.Conv2dNormActivation/features.3.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_7: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J›
pkg.torch.onnx.fx_node¬%_native_batch_norm_legit_no_training_7 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_9, %p_features_3_block_1_1_weight, %p_features_3_block_1_1_bias, %b_features_3_block_1_1_running_mean, %b_features_3_block_1_1_running_var, 0.01, 0.001), kwargs = {})J©
pkg.torch.onnx.name_scopesä['', 'features', 'features.3', 'features.3.block', 'features.3.block.1', 'features.3.block.1.1', '_native_batch_norm_legit_no_training_7']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
Ë

getitem_21relu_5node_relu_5"ReluJ‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.3: torchvision.models.mobilenetv3.InvertedResidual/features.3.block: torch.nn.modules.container.Sequential/features.3.block.1: torchvision.ops.misc.Conv2dNormActivation/features.3.block.1.2: torch.nn.modules.activation.ReLU/relu_5: aten.relu.defaultJ´
pkg.torch.onnx.class_hierarchyà['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jâ
pkg.torch.onnx.fx_nodeo%relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_21,), kwargs = {})Jà
pkg.torch.onnx.name_scopesj['', 'features', 'features.3', 'features.3.block', 'features.3.block.1', 'features.3.block.1.2', 'relu_5']Jö	
pkg.torch.onnx.stack_trace˚File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
™
relu_5
features.3.block.2.0.weight
 features.3.block.2.0.weight_bias
getitem_24node_Conv_453"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.3: torchvision.models.mobilenetv3.InvertedResidual/features.3.block: torch.nn.modules.container.Sequential/features.3.block.2: torchvision.ops.misc.Conv2dNormActivation/features.3.block.2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_8: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬁ
pkg.torch.onnx.fx_node√%_native_batch_norm_legit_no_training_8 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_10, %p_features_3_block_2_1_weight, %p_features_3_block_2_1_bias, %b_features_3_block_2_1_running_mean, %b_features_3_block_2_1_running_var, 0.01, 0.001), kwargs = {})J©
pkg.torch.onnx.name_scopesä['', 'features', 'features.3', 'features.3.block', 'features.3.block.2', 'features.3.block.2.1', '_native_batch_norm_legit_no_training_8']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
π	

getitem_24

getitem_15add_503node_add_503"AddJÆ
	namespace†: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.3: torchvision.models.mobilenetv3.InvertedResidual/add_503: aten.add.TensorJØ
pkg.torch.onnx.class_hierarchyå['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_503 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_24, %getitem_15), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'features', 'features.3', 'add_503']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 114, in forward
    result += input
´
add_503
features.4.block.0.0.weight
 features.4.block.0.0.weight_bias
getitem_27node_Conv_455"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.0: torchvision.ops.misc.Conv2dNormActivation/features.4.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_9: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬁ
pkg.torch.onnx.fx_node√%_native_batch_norm_legit_no_training_9 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_11, %p_features_4_block_0_1_weight, %p_features_4_block_0_1_bias, %b_features_4_block_0_1_running_mean, %b_features_4_block_0_1_running_var, 0.01, 0.001), kwargs = {})J©
pkg.torch.onnx.name_scopesä['', 'features', 'features.4', 'features.4.block', 'features.4.block.0', 'features.4.block.0.1', '_native_batch_norm_legit_no_training_9']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ê

getitem_27hardswish_1n0_2"	HardSwishJÎ
	namespace›: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.0: torchvision.ops.misc.Conv2dNormActivation/features.4.block.0.2: torch.nn.modules.activation.Hardswish/hardswish_1: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jì
pkg.torch.onnx.fx_nodey%hardswish_1 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_27,), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.4', 'features.4.block', 'features.4.block.0', 'features.4.block.0.2', 'hardswish_1']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
≤
hardswish_1
features.4.block.1.0.weight
 features.4.block.1.0.weight_bias
getitem_30node_Conv_457"Conv*
group`†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.1: torchvision.ops.misc.Conv2dNormActivation/features.4.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_10: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_10 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_12, %p_features_4_block_1_1_weight, %p_features_4_block_1_1_bias, %b_features_4_block_1_1_running_mean, %b_features_4_block_1_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.4', 'features.4.block', 'features.4.block.1', 'features.4.block.1.1', '_native_batch_norm_legit_no_training_10']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ê

getitem_30hardswish_2n0_3"	HardSwishJÎ
	namespace›: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.1: torchvision.ops.misc.Conv2dNormActivation/features.4.block.1.2: torch.nn.modules.activation.Hardswish/hardswish_2: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jì
pkg.torch.onnx.fx_nodey%hardswish_2 : [num_users=2] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_30,), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.4', 'features.4.block', 'features.4.block.1', 'features.4.block.1.2', 'hardswish_2']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
À
hardswish_2
val_23mean_1node_mean_1"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÂ
	namespace◊: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.2: torchvision.ops.misc.SqueezeExcitation/features.4.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_1: aten.mean.dimJÆ
pkg.torch.onnx.class_hierarchyã['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jï
pkg.torch.onnx.fx_node{%mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%hardswish_2, [-1, -2], True), kwargs = {})Jé
pkg.torch.onnx.name_scopesp['', 'features', 'features.4', 'features.4.block', 'features.4.block.2', 'features.4.block.2.avgpool', 'mean_1']J¢	
pkg.torch.onnx.stack_traceÉ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
Œ
mean_1
features.4.block.2.fc1.weight
features.4.block.2.fc1.bias	conv2d_13node_conv2d_13"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.2: torchvision.ops.misc.SqueezeExcitation/features.4.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_13: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_13 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_1, %p_features_4_block_2_fc1_weight, %p_features_4_block_2_fc1_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.4', 'features.4.block', 'features.4.block.2', 'features.4.block.2.fc1', 'conv2d_13']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Ò
	conv2d_13relu_6node_relu_6"ReluJ‚
	namespace‘: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.2: torchvision.ops.misc.SqueezeExcitation/features.4.block.2.activation: torch.nn.modules.activation.ReLU/relu_6: aten.relu.defaultJ®
pkg.torch.onnx.class_hierarchyÖ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jà
pkg.torch.onnx.fx_noden%relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%conv2d_13,), kwargs = {})Jë
pkg.torch.onnx.name_scopess['', 'features', 'features.4', 'features.4.block', 'features.4.block.2', 'features.4.block.2.activation', 'relu_6']Jô	
pkg.torch.onnx.stack_trace˙File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
Œ
relu_6
features.4.block.2.fc2.weight
features.4.block.2.fc2.bias	conv2d_14node_conv2d_14"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.2: torchvision.ops.misc.SqueezeExcitation/features.4.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_14: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_14 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_6, %p_features_4_block_2_fc2_weight, %p_features_4_block_2_fc2_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.4', 'features.4.block', 'features.4.block.2', 'features.4.block.2.fc2', 'conv2d_14']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Î
	conv2d_14hardsigmoid_1node_hardsigmoid_1"HardSigmoid*
beta   ?†*
alpha´™*>†J˝
	namespaceÔ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.2: torchvision.ops.misc.SqueezeExcitation/features.4.block.2.scale_activation: torch.nn.modules.activation.Hardsigmoid/hardsigmoid_1: aten.hardsigmoid.defaultJ∂
pkg.torch.onnx.class_hierarchyì['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Hardsigmoid', 'aten.hardsigmoid.default']Jñ
pkg.torch.onnx.fx_node|%hardsigmoid_1 : [num_users=1] = call_function[target=torch.ops.aten.hardsigmoid.default](args = (%conv2d_14,), kwargs = {})Jü
pkg.torch.onnx.name_scopesÄ['', 'features', 'features.4', 'features.4.block', 'features.4.block.2', 'features.4.block.2.scale_activation', 'hardsigmoid_1']Jò	
pkg.torch.onnx.stack_trace˘File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 402, in forward
    return F.hardsigmoid(input, self.inplace)
±
hardsigmoid_1
hardswish_2mul_811node_mul_811"MulJ°
	namespaceì: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.2: torchvision.ops.misc.SqueezeExcitation/mul_811: aten.mul.TensorJÇ
pkg.torch.onnx.class_hierarchyﬂ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jò
pkg.torch.onnx.fx_node~%mul_811 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%hardsigmoid_1, %hardswish_2), kwargs = {})Jq
pkg.torch.onnx.name_scopesS['', 'features', 'features.4', 'features.4.block', 'features.4.block.2', 'mul_811']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Æ
mul_811
features.4.block.3.0.weight
 features.4.block.3.0.weight_bias
getitem_33node_Conv_459"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.4: torchvision.models.mobilenetv3.InvertedResidual/features.4.block: torch.nn.modules.container.Sequential/features.4.block.3: torchvision.ops.misc.Conv2dNormActivation/features.4.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_11: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_11 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_15, %p_features_4_block_3_1_weight, %p_features_4_block_3_1_bias, %b_features_4_block_3_1_running_mean, %b_features_4_block_3_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.4', 'features.4.block', 'features.4.block.3', 'features.4.block.3.1', '_native_batch_norm_legit_no_training_11']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
±

getitem_33
features.5.block.0.0.weight
 features.5.block.0.0.weight_bias
getitem_36node_Conv_461"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.0: torchvision.ops.misc.Conv2dNormActivation/features.5.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_12: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_12 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_16, %p_features_5_block_0_1_weight, %p_features_5_block_0_1_bias, %b_features_5_block_0_1_running_mean, %b_features_5_block_0_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.5', 'features.5.block', 'features.5.block.0', 'features.5.block.0.1', '_native_batch_norm_legit_no_training_12']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ê

getitem_36hardswish_3n0_4"	HardSwishJÎ
	namespace›: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.0: torchvision.ops.misc.Conv2dNormActivation/features.5.block.0.2: torch.nn.modules.activation.Hardswish/hardswish_3: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jì
pkg.torch.onnx.fx_nodey%hardswish_3 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_36,), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.5', 'features.5.block', 'features.5.block.0', 'features.5.block.0.2', 'hardswish_3']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
≥
hardswish_3
features.5.block.1.0.weight
 features.5.block.1.0.weight_bias
getitem_39node_Conv_463"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.1: torchvision.ops.misc.Conv2dNormActivation/features.5.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_13: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_13 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_17, %p_features_5_block_1_1_weight, %p_features_5_block_1_1_bias, %b_features_5_block_1_1_running_mean, %b_features_5_block_1_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.5', 'features.5.block', 'features.5.block.1', 'features.5.block.1.1', '_native_batch_norm_legit_no_training_13']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ê

getitem_39hardswish_4n0_5"	HardSwishJÎ
	namespace›: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.1: torchvision.ops.misc.Conv2dNormActivation/features.5.block.1.2: torch.nn.modules.activation.Hardswish/hardswish_4: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jì
pkg.torch.onnx.fx_nodey%hardswish_4 : [num_users=2] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_39,), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.5', 'features.5.block', 'features.5.block.1', 'features.5.block.1.2', 'hardswish_4']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
À
hardswish_4
val_23mean_2node_mean_2"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÂ
	namespace◊: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.2: torchvision.ops.misc.SqueezeExcitation/features.5.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_2: aten.mean.dimJÆ
pkg.torch.onnx.class_hierarchyã['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jï
pkg.torch.onnx.fx_node{%mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%hardswish_4, [-1, -2], True), kwargs = {})Jé
pkg.torch.onnx.name_scopesp['', 'features', 'features.5', 'features.5.block', 'features.5.block.2', 'features.5.block.2.avgpool', 'mean_2']J¢	
pkg.torch.onnx.stack_traceÉ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
Œ
mean_2
features.5.block.2.fc1.weight
features.5.block.2.fc1.bias	conv2d_18node_conv2d_18"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.2: torchvision.ops.misc.SqueezeExcitation/features.5.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_18: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_18 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_2, %p_features_5_block_2_fc1_weight, %p_features_5_block_2_fc1_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.5', 'features.5.block', 'features.5.block.2', 'features.5.block.2.fc1', 'conv2d_18']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Ò
	conv2d_18relu_7node_relu_7"ReluJ‚
	namespace‘: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.2: torchvision.ops.misc.SqueezeExcitation/features.5.block.2.activation: torch.nn.modules.activation.ReLU/relu_7: aten.relu.defaultJ®
pkg.torch.onnx.class_hierarchyÖ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jà
pkg.torch.onnx.fx_noden%relu_7 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%conv2d_18,), kwargs = {})Jë
pkg.torch.onnx.name_scopess['', 'features', 'features.5', 'features.5.block', 'features.5.block.2', 'features.5.block.2.activation', 'relu_7']Jô	
pkg.torch.onnx.stack_trace˙File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
Œ
relu_7
features.5.block.2.fc2.weight
features.5.block.2.fc2.bias	conv2d_19node_conv2d_19"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.2: torchvision.ops.misc.SqueezeExcitation/features.5.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_19: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_19 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_7, %p_features_5_block_2_fc2_weight, %p_features_5_block_2_fc2_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.5', 'features.5.block', 'features.5.block.2', 'features.5.block.2.fc2', 'conv2d_19']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Î
	conv2d_19hardsigmoid_2node_hardsigmoid_2"HardSigmoid*
beta   ?†*
alpha´™*>†J˝
	namespaceÔ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.2: torchvision.ops.misc.SqueezeExcitation/features.5.block.2.scale_activation: torch.nn.modules.activation.Hardsigmoid/hardsigmoid_2: aten.hardsigmoid.defaultJ∂
pkg.torch.onnx.class_hierarchyì['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Hardsigmoid', 'aten.hardsigmoid.default']Jñ
pkg.torch.onnx.fx_node|%hardsigmoid_2 : [num_users=1] = call_function[target=torch.ops.aten.hardsigmoid.default](args = (%conv2d_19,), kwargs = {})Jü
pkg.torch.onnx.name_scopesÄ['', 'features', 'features.5', 'features.5.block', 'features.5.block.2', 'features.5.block.2.scale_activation', 'hardsigmoid_2']Jò	
pkg.torch.onnx.stack_trace˘File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 402, in forward
    return F.hardsigmoid(input, self.inplace)
∂
hardsigmoid_2
hardswish_4mul_1125node_mul_1125"MulJ¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1125: aten.mul.TensorJÇ
pkg.torch.onnx.class_hierarchyﬂ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jô
pkg.torch.onnx.fx_node%mul_1125 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%hardsigmoid_2, %hardswish_4), kwargs = {})Jr
pkg.torch.onnx.name_scopesT['', 'features', 'features.5', 'features.5.block', 'features.5.block.2', 'mul_1125']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Ø
mul_1125
features.5.block.3.0.weight
 features.5.block.3.0.weight_bias
getitem_42node_Conv_465"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/features.5.block: torch.nn.modules.container.Sequential/features.5.block.3: torchvision.ops.misc.Conv2dNormActivation/features.5.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_14: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_14 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_20, %p_features_5_block_3_1_weight, %p_features_5_block_3_1_bias, %b_features_5_block_3_1_running_mean, %b_features_5_block_3_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.5', 'features.5.block', 'features.5.block.3', 'features.5.block.3.1', '_native_batch_norm_legit_no_training_14']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
π	

getitem_42

getitem_33add_648node_add_648"AddJÆ
	namespace†: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.5: torchvision.models.mobilenetv3.InvertedResidual/add_648: aten.add.TensorJØ
pkg.torch.onnx.class_hierarchyå['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_648 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_42, %getitem_33), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'features', 'features.5', 'add_648']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 114, in forward
    result += input
Æ
add_648
features.6.block.0.0.weight
 features.6.block.0.0.weight_bias
getitem_45node_Conv_467"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.0: torchvision.ops.misc.Conv2dNormActivation/features.6.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_15: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_15 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_21, %p_features_6_block_0_1_weight, %p_features_6_block_0_1_bias, %b_features_6_block_0_1_running_mean, %b_features_6_block_0_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.6', 'features.6.block', 'features.6.block.0', 'features.6.block.0.1', '_native_batch_norm_legit_no_training_15']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ê

getitem_45hardswish_5n0_6"	HardSwishJÎ
	namespace›: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.0: torchvision.ops.misc.Conv2dNormActivation/features.6.block.0.2: torch.nn.modules.activation.Hardswish/hardswish_5: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jì
pkg.torch.onnx.fx_nodey%hardswish_5 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_45,), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.6', 'features.6.block', 'features.6.block.0', 'features.6.block.0.2', 'hardswish_5']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
≥
hardswish_5
features.6.block.1.0.weight
 features.6.block.1.0.weight_bias
getitem_48node_Conv_469"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.1: torchvision.ops.misc.Conv2dNormActivation/features.6.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_16: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_16 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_22, %p_features_6_block_1_1_weight, %p_features_6_block_1_1_bias, %b_features_6_block_1_1_running_mean, %b_features_6_block_1_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.6', 'features.6.block', 'features.6.block.1', 'features.6.block.1.1', '_native_batch_norm_legit_no_training_16']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ê

getitem_48hardswish_6n0_7"	HardSwishJÎ
	namespace›: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.1: torchvision.ops.misc.Conv2dNormActivation/features.6.block.1.2: torch.nn.modules.activation.Hardswish/hardswish_6: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jì
pkg.torch.onnx.fx_nodey%hardswish_6 : [num_users=2] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_48,), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.6', 'features.6.block', 'features.6.block.1', 'features.6.block.1.2', 'hardswish_6']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
À
hardswish_6
val_23mean_3node_mean_3"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÂ
	namespace◊: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.2: torchvision.ops.misc.SqueezeExcitation/features.6.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_3: aten.mean.dimJÆ
pkg.torch.onnx.class_hierarchyã['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jï
pkg.torch.onnx.fx_node{%mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%hardswish_6, [-1, -2], True), kwargs = {})Jé
pkg.torch.onnx.name_scopesp['', 'features', 'features.6', 'features.6.block', 'features.6.block.2', 'features.6.block.2.avgpool', 'mean_3']J¢	
pkg.torch.onnx.stack_traceÉ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
Œ
mean_3
features.6.block.2.fc1.weight
features.6.block.2.fc1.bias	conv2d_23node_conv2d_23"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.2: torchvision.ops.misc.SqueezeExcitation/features.6.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_23: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_23 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_3, %p_features_6_block_2_fc1_weight, %p_features_6_block_2_fc1_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.6', 'features.6.block', 'features.6.block.2', 'features.6.block.2.fc1', 'conv2d_23']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Ò
	conv2d_23relu_8node_relu_8"ReluJ‚
	namespace‘: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.2: torchvision.ops.misc.SqueezeExcitation/features.6.block.2.activation: torch.nn.modules.activation.ReLU/relu_8: aten.relu.defaultJ®
pkg.torch.onnx.class_hierarchyÖ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jà
pkg.torch.onnx.fx_noden%relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%conv2d_23,), kwargs = {})Jë
pkg.torch.onnx.name_scopess['', 'features', 'features.6', 'features.6.block', 'features.6.block.2', 'features.6.block.2.activation', 'relu_8']Jô	
pkg.torch.onnx.stack_trace˙File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
Œ
relu_8
features.6.block.2.fc2.weight
features.6.block.2.fc2.bias	conv2d_24node_conv2d_24"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.2: torchvision.ops.misc.SqueezeExcitation/features.6.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_24: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_24 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_8, %p_features_6_block_2_fc2_weight, %p_features_6_block_2_fc2_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.6', 'features.6.block', 'features.6.block.2', 'features.6.block.2.fc2', 'conv2d_24']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Î
	conv2d_24hardsigmoid_3node_hardsigmoid_3"HardSigmoid*
beta   ?†*
alpha´™*>†J˝
	namespaceÔ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.2: torchvision.ops.misc.SqueezeExcitation/features.6.block.2.scale_activation: torch.nn.modules.activation.Hardsigmoid/hardsigmoid_3: aten.hardsigmoid.defaultJ∂
pkg.torch.onnx.class_hierarchyì['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Hardsigmoid', 'aten.hardsigmoid.default']Jñ
pkg.torch.onnx.fx_node|%hardsigmoid_3 : [num_users=1] = call_function[target=torch.ops.aten.hardsigmoid.default](args = (%conv2d_24,), kwargs = {})Jü
pkg.torch.onnx.name_scopesÄ['', 'features', 'features.6', 'features.6.block', 'features.6.block.2', 'features.6.block.2.scale_activation', 'hardsigmoid_3']Jò	
pkg.torch.onnx.stack_trace˘File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 402, in forward
    return F.hardsigmoid(input, self.inplace)
∂
hardsigmoid_3
hardswish_6mul_1451node_mul_1451"MulJ¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1451: aten.mul.TensorJÇ
pkg.torch.onnx.class_hierarchyﬂ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jô
pkg.torch.onnx.fx_node%mul_1451 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%hardsigmoid_3, %hardswish_6), kwargs = {})Jr
pkg.torch.onnx.name_scopesT['', 'features', 'features.6', 'features.6.block', 'features.6.block.2', 'mul_1451']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Ø
mul_1451
features.6.block.3.0.weight
 features.6.block.3.0.weight_bias
getitem_51node_Conv_471"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/features.6.block: torch.nn.modules.container.Sequential/features.6.block.3: torchvision.ops.misc.Conv2dNormActivation/features.6.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_17: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_17 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_25, %p_features_6_block_3_1_weight, %p_features_6_block_3_1_bias, %b_features_6_block_3_1_running_mean, %b_features_6_block_3_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.6', 'features.6.block', 'features.6.block.3', 'features.6.block.3.1', '_native_batch_norm_legit_no_training_17']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
≥	

getitem_51
add_648add_727node_add_727"AddJÆ
	namespace†: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.6: torchvision.models.mobilenetv3.InvertedResidual/add_727: aten.add.TensorJØ
pkg.torch.onnx.class_hierarchyå['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'aten.add.Tensor']Jë
pkg.torch.onnx.fx_nodew%add_727 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_51, %add_648), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'features', 'features.6', 'add_727']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 114, in forward
    result += input
Æ
add_727
features.7.block.0.0.weight
 features.7.block.0.0.weight_bias
getitem_54node_Conv_473"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.0: torchvision.ops.misc.Conv2dNormActivation/features.7.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_18: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_18 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_26, %p_features_7_block_0_1_weight, %p_features_7_block_0_1_bias, %b_features_7_block_0_1_running_mean, %b_features_7_block_0_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.7', 'features.7.block', 'features.7.block.0', 'features.7.block.0.1', '_native_batch_norm_legit_no_training_18']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ê

getitem_54hardswish_7n0_8"	HardSwishJÎ
	namespace›: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.0: torchvision.ops.misc.Conv2dNormActivation/features.7.block.0.2: torch.nn.modules.activation.Hardswish/hardswish_7: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jì
pkg.torch.onnx.fx_nodey%hardswish_7 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_54,), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.7', 'features.7.block', 'features.7.block.0', 'features.7.block.0.2', 'hardswish_7']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
≤
hardswish_7
features.7.block.1.0.weight
 features.7.block.1.0.weight_bias
getitem_57node_Conv_475"Conv*
groupx†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.1: torchvision.ops.misc.Conv2dNormActivation/features.7.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_19: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_19 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_27, %p_features_7_block_1_1_weight, %p_features_7_block_1_1_bias, %b_features_7_block_1_1_running_mean, %b_features_7_block_1_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.7', 'features.7.block', 'features.7.block.1', 'features.7.block.1.1', '_native_batch_norm_legit_no_training_19']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ê

getitem_57hardswish_8n0_9"	HardSwishJÎ
	namespace›: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.1: torchvision.ops.misc.Conv2dNormActivation/features.7.block.1.2: torch.nn.modules.activation.Hardswish/hardswish_8: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jì
pkg.torch.onnx.fx_nodey%hardswish_8 : [num_users=2] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_57,), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.7', 'features.7.block', 'features.7.block.1', 'features.7.block.1.2', 'hardswish_8']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
À
hardswish_8
val_23mean_4node_mean_4"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÂ
	namespace◊: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.2: torchvision.ops.misc.SqueezeExcitation/features.7.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_4: aten.mean.dimJÆ
pkg.torch.onnx.class_hierarchyã['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jï
pkg.torch.onnx.fx_node{%mean_4 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%hardswish_8, [-1, -2], True), kwargs = {})Jé
pkg.torch.onnx.name_scopesp['', 'features', 'features.7', 'features.7.block', 'features.7.block.2', 'features.7.block.2.avgpool', 'mean_4']J¢	
pkg.torch.onnx.stack_traceÉ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
Œ
mean_4
features.7.block.2.fc1.weight
features.7.block.2.fc1.bias	conv2d_28node_conv2d_28"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.2: torchvision.ops.misc.SqueezeExcitation/features.7.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_28: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_28 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_4, %p_features_7_block_2_fc1_weight, %p_features_7_block_2_fc1_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.7', 'features.7.block', 'features.7.block.2', 'features.7.block.2.fc1', 'conv2d_28']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Ò
	conv2d_28relu_9node_relu_9"ReluJ‚
	namespace‘: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.2: torchvision.ops.misc.SqueezeExcitation/features.7.block.2.activation: torch.nn.modules.activation.ReLU/relu_9: aten.relu.defaultJ®
pkg.torch.onnx.class_hierarchyÖ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jà
pkg.torch.onnx.fx_noden%relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%conv2d_28,), kwargs = {})Jë
pkg.torch.onnx.name_scopess['', 'features', 'features.7', 'features.7.block', 'features.7.block.2', 'features.7.block.2.activation', 'relu_9']Jô	
pkg.torch.onnx.stack_trace˙File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
Œ
relu_9
features.7.block.2.fc2.weight
features.7.block.2.fc2.bias	conv2d_29node_conv2d_29"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.2: torchvision.ops.misc.SqueezeExcitation/features.7.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_29: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_29 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_9, %p_features_7_block_2_fc2_weight, %p_features_7_block_2_fc2_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.7', 'features.7.block', 'features.7.block.2', 'features.7.block.2.fc2', 'conv2d_29']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Î
	conv2d_29hardsigmoid_4node_hardsigmoid_4"HardSigmoid*
beta   ?†*
alpha´™*>†J˝
	namespaceÔ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.2: torchvision.ops.misc.SqueezeExcitation/features.7.block.2.scale_activation: torch.nn.modules.activation.Hardsigmoid/hardsigmoid_4: aten.hardsigmoid.defaultJ∂
pkg.torch.onnx.class_hierarchyì['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Hardsigmoid', 'aten.hardsigmoid.default']Jñ
pkg.torch.onnx.fx_node|%hardsigmoid_4 : [num_users=1] = call_function[target=torch.ops.aten.hardsigmoid.default](args = (%conv2d_29,), kwargs = {})Jü
pkg.torch.onnx.name_scopesÄ['', 'features', 'features.7', 'features.7.block', 'features.7.block.2', 'features.7.block.2.scale_activation', 'hardsigmoid_4']Jò	
pkg.torch.onnx.stack_trace˘File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 402, in forward
    return F.hardsigmoid(input, self.inplace)
∂
hardsigmoid_4
hardswish_8mul_1777node_mul_1777"MulJ¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1777: aten.mul.TensorJÇ
pkg.torch.onnx.class_hierarchyﬂ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jô
pkg.torch.onnx.fx_node%mul_1777 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%hardsigmoid_4, %hardswish_8), kwargs = {})Jr
pkg.torch.onnx.name_scopesT['', 'features', 'features.7', 'features.7.block', 'features.7.block.2', 'mul_1777']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Ø
mul_1777
features.7.block.3.0.weight
 features.7.block.3.0.weight_bias
getitem_60node_Conv_477"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.7: torchvision.models.mobilenetv3.InvertedResidual/features.7.block: torch.nn.modules.container.Sequential/features.7.block.3: torchvision.ops.misc.Conv2dNormActivation/features.7.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_20: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_20 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_30, %p_features_7_block_3_1_weight, %p_features_7_block_3_1_bias, %b_features_7_block_3_1_running_mean, %b_features_7_block_3_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.7', 'features.7.block', 'features.7.block.3', 'features.7.block.3.1', '_native_batch_norm_legit_no_training_20']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
±

getitem_60
features.8.block.0.0.weight
 features.8.block.0.0.weight_bias
getitem_63node_Conv_479"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.0: torchvision.ops.misc.Conv2dNormActivation/features.8.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_21: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_21 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_31, %p_features_8_block_0_1_weight, %p_features_8_block_0_1_bias, %b_features_8_block_0_1_running_mean, %b_features_8_block_0_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.8', 'features.8.block', 'features.8.block.0', 'features.8.block.0.1', '_native_batch_norm_legit_no_training_21']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ë

getitem_63hardswish_9n0_10"	HardSwishJÎ
	namespace›: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.0: torchvision.ops.misc.Conv2dNormActivation/features.8.block.0.2: torch.nn.modules.activation.Hardswish/hardswish_9: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jì
pkg.torch.onnx.fx_nodey%hardswish_9 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_63,), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.8', 'features.8.block', 'features.8.block.0', 'features.8.block.0.2', 'hardswish_9']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
≥
hardswish_9
features.8.block.1.0.weight
 features.8.block.1.0.weight_bias
getitem_66node_Conv_481"Conv*
groupê†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.1: torchvision.ops.misc.Conv2dNormActivation/features.8.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_22: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_22 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_32, %p_features_8_block_1_1_weight, %p_features_8_block_1_1_bias, %b_features_8_block_1_1_running_mean, %b_features_8_block_1_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.8', 'features.8.block', 'features.8.block.1', 'features.8.block.1.1', '_native_batch_norm_legit_no_training_22']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ï

getitem_66hardswish_10n0_11"	HardSwishJÏ
	namespaceﬁ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.1: torchvision.ops.misc.Conv2dNormActivation/features.8.block.1.2: torch.nn.modules.activation.Hardswish/hardswish_10: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jî
pkg.torch.onnx.fx_nodez%hardswish_10 : [num_users=2] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_66,), kwargs = {})Jé
pkg.torch.onnx.name_scopesp['', 'features', 'features.8', 'features.8.block', 'features.8.block.1', 'features.8.block.1.2', 'hardswish_10']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
Õ
hardswish_10
val_23mean_5node_mean_5"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÂ
	namespace◊: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.2: torchvision.ops.misc.SqueezeExcitation/features.8.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_5: aten.mean.dimJÆ
pkg.torch.onnx.class_hierarchyã['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jñ
pkg.torch.onnx.fx_node|%mean_5 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%hardswish_10, [-1, -2], True), kwargs = {})Jé
pkg.torch.onnx.name_scopesp['', 'features', 'features.8', 'features.8.block', 'features.8.block.2', 'features.8.block.2.avgpool', 'mean_5']J¢	
pkg.torch.onnx.stack_traceÉ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
Œ
mean_5
features.8.block.2.fc1.weight
features.8.block.2.fc1.bias	conv2d_33node_conv2d_33"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.2: torchvision.ops.misc.SqueezeExcitation/features.8.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_33: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_33 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_5, %p_features_8_block_2_fc1_weight, %p_features_8_block_2_fc1_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.8', 'features.8.block', 'features.8.block.2', 'features.8.block.2.fc1', 'conv2d_33']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
ˆ
	conv2d_33relu_10node_relu_10"ReluJ„
	namespace’: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.2: torchvision.ops.misc.SqueezeExcitation/features.8.block.2.activation: torch.nn.modules.activation.ReLU/relu_10: aten.relu.defaultJ®
pkg.torch.onnx.class_hierarchyÖ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jâ
pkg.torch.onnx.fx_nodeo%relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%conv2d_33,), kwargs = {})Jí
pkg.torch.onnx.name_scopest['', 'features', 'features.8', 'features.8.block', 'features.8.block.2', 'features.8.block.2.activation', 'relu_10']Jô	
pkg.torch.onnx.stack_trace˙File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
–
relu_10
features.8.block.2.fc2.weight
features.8.block.2.fc2.bias	conv2d_34node_conv2d_34"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.2: torchvision.ops.misc.SqueezeExcitation/features.8.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_34: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÕ
pkg.torch.onnx.fx_node≤%conv2d_34 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_10, %p_features_8_block_2_fc2_weight, %p_features_8_block_2_fc2_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.8', 'features.8.block', 'features.8.block.2', 'features.8.block.2.fc2', 'conv2d_34']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Î
	conv2d_34hardsigmoid_5node_hardsigmoid_5"HardSigmoid*
beta   ?†*
alpha´™*>†J˝
	namespaceÔ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.2: torchvision.ops.misc.SqueezeExcitation/features.8.block.2.scale_activation: torch.nn.modules.activation.Hardsigmoid/hardsigmoid_5: aten.hardsigmoid.defaultJ∂
pkg.torch.onnx.class_hierarchyì['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Hardsigmoid', 'aten.hardsigmoid.default']Jñ
pkg.torch.onnx.fx_node|%hardsigmoid_5 : [num_users=1] = call_function[target=torch.ops.aten.hardsigmoid.default](args = (%conv2d_34,), kwargs = {})Jü
pkg.torch.onnx.name_scopesÄ['', 'features', 'features.8', 'features.8.block', 'features.8.block.2', 'features.8.block.2.scale_activation', 'hardsigmoid_5']Jò	
pkg.torch.onnx.stack_trace˘File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 402, in forward
    return F.hardsigmoid(input, self.inplace)
π
hardsigmoid_5
hardswish_10mul_2091node_mul_2091"MulJ¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2091: aten.mul.TensorJÇ
pkg.torch.onnx.class_hierarchyﬂ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jõ
pkg.torch.onnx.fx_nodeÄ%mul_2091 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%hardsigmoid_5, %hardswish_10), kwargs = {})Jr
pkg.torch.onnx.name_scopesT['', 'features', 'features.8', 'features.8.block', 'features.8.block.2', 'mul_2091']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Ø
mul_2091
features.8.block.3.0.weight
 features.8.block.3.0.weight_bias
getitem_69node_Conv_483"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/features.8.block: torch.nn.modules.container.Sequential/features.8.block.3: torchvision.ops.misc.Conv2dNormActivation/features.8.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_23: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_23 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_35, %p_features_8_block_3_1_weight, %p_features_8_block_3_1_bias, %b_features_8_block_3_1_running_mean, %b_features_8_block_3_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.8', 'features.8.block', 'features.8.block.3', 'features.8.block.3.1', '_native_batch_norm_legit_no_training_23']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
π	

getitem_69

getitem_60add_872node_add_872"AddJÆ
	namespace†: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.8: torchvision.models.mobilenetv3.InvertedResidual/add_872: aten.add.TensorJØ
pkg.torch.onnx.class_hierarchyå['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_872 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_69, %getitem_60), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'features', 'features.8', 'add_872']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 114, in forward
    result += input
Æ
add_872
features.9.block.0.0.weight
 features.9.block.0.0.weight_bias
getitem_72node_Conv_485"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.0: torchvision.ops.misc.Conv2dNormActivation/features.9.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_24: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_24 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_36, %p_features_9_block_0_1_weight, %p_features_9_block_0_1_bias, %b_features_9_block_0_1_running_mean, %b_features_9_block_0_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.9', 'features.9.block', 'features.9.block.0', 'features.9.block.0.1', '_native_batch_norm_legit_no_training_24']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ï

getitem_72hardswish_11n0_12"	HardSwishJÏ
	namespaceﬁ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.0: torchvision.ops.misc.Conv2dNormActivation/features.9.block.0.2: torch.nn.modules.activation.Hardswish/hardswish_11: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jî
pkg.torch.onnx.fx_nodez%hardswish_11 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_72,), kwargs = {})Jé
pkg.torch.onnx.name_scopesp['', 'features', 'features.9', 'features.9.block', 'features.9.block.0', 'features.9.block.0.2', 'hardswish_11']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
¥
hardswish_11
features.9.block.1.0.weight
 features.9.block.1.0.weight_bias
getitem_75node_Conv_487"Conv*
group††*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.1: torchvision.ops.misc.Conv2dNormActivation/features.9.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_25: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_25 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_37, %p_features_9_block_1_1_weight, %p_features_9_block_1_1_bias, %b_features_9_block_1_1_running_mean, %b_features_9_block_1_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.9', 'features.9.block', 'features.9.block.1', 'features.9.block.1.1', '_native_batch_norm_legit_no_training_25']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ï

getitem_75hardswish_12n0_13"	HardSwishJÏ
	namespaceﬁ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.1: torchvision.ops.misc.Conv2dNormActivation/features.9.block.1.2: torch.nn.modules.activation.Hardswish/hardswish_12: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jî
pkg.torch.onnx.fx_nodez%hardswish_12 : [num_users=2] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_75,), kwargs = {})Jé
pkg.torch.onnx.name_scopesp['', 'features', 'features.9', 'features.9.block', 'features.9.block.1', 'features.9.block.1.2', 'hardswish_12']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
Õ
hardswish_12
val_23mean_6node_mean_6"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÂ
	namespace◊: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.2: torchvision.ops.misc.SqueezeExcitation/features.9.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_6: aten.mean.dimJÆ
pkg.torch.onnx.class_hierarchyã['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jñ
pkg.torch.onnx.fx_node|%mean_6 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%hardswish_12, [-1, -2], True), kwargs = {})Jé
pkg.torch.onnx.name_scopesp['', 'features', 'features.9', 'features.9.block', 'features.9.block.2', 'features.9.block.2.avgpool', 'mean_6']J¢	
pkg.torch.onnx.stack_traceÉ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
Œ
mean_6
features.9.block.2.fc1.weight
features.9.block.2.fc1.bias	conv2d_38node_conv2d_38"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.2: torchvision.ops.misc.SqueezeExcitation/features.9.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_38: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÃ
pkg.torch.onnx.fx_node±%conv2d_38 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_6, %p_features_9_block_2_fc1_weight, %p_features_9_block_2_fc1_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.9', 'features.9.block', 'features.9.block.2', 'features.9.block.2.fc1', 'conv2d_38']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
ˆ
	conv2d_38relu_11node_relu_11"ReluJ„
	namespace’: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.2: torchvision.ops.misc.SqueezeExcitation/features.9.block.2.activation: torch.nn.modules.activation.ReLU/relu_11: aten.relu.defaultJ®
pkg.torch.onnx.class_hierarchyÖ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jâ
pkg.torch.onnx.fx_nodeo%relu_11 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%conv2d_38,), kwargs = {})Jí
pkg.torch.onnx.name_scopest['', 'features', 'features.9', 'features.9.block', 'features.9.block.2', 'features.9.block.2.activation', 'relu_11']Jô	
pkg.torch.onnx.stack_trace˙File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
–
relu_11
features.9.block.2.fc2.weight
features.9.block.2.fc2.bias	conv2d_39node_conv2d_39"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‹
	namespaceŒ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.2: torchvision.ops.misc.SqueezeExcitation/features.9.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_39: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÕ
pkg.torch.onnx.fx_node≤%conv2d_39 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_11, %p_features_9_block_2_fc2_weight, %p_features_9_block_2_fc2_bias), kwargs = {})Jç
pkg.torch.onnx.name_scopeso['', 'features', 'features.9', 'features.9.block', 'features.9.block.2', 'features.9.block.2.fc2', 'conv2d_39']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Î
	conv2d_39hardsigmoid_6node_hardsigmoid_6"HardSigmoid*
beta   ?†*
alpha´™*>†J˝
	namespaceÔ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.2: torchvision.ops.misc.SqueezeExcitation/features.9.block.2.scale_activation: torch.nn.modules.activation.Hardsigmoid/hardsigmoid_6: aten.hardsigmoid.defaultJ∂
pkg.torch.onnx.class_hierarchyì['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Hardsigmoid', 'aten.hardsigmoid.default']Jñ
pkg.torch.onnx.fx_node|%hardsigmoid_6 : [num_users=1] = call_function[target=torch.ops.aten.hardsigmoid.default](args = (%conv2d_39,), kwargs = {})Jü
pkg.torch.onnx.name_scopesÄ['', 'features', 'features.9', 'features.9.block', 'features.9.block.2', 'features.9.block.2.scale_activation', 'hardsigmoid_6']Jò	
pkg.torch.onnx.stack_trace˘File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 402, in forward
    return F.hardsigmoid(input, self.inplace)
π
hardsigmoid_6
hardswish_12mul_2417node_mul_2417"MulJ¢
	namespaceî: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2417: aten.mul.TensorJÇ
pkg.torch.onnx.class_hierarchyﬂ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jõ
pkg.torch.onnx.fx_nodeÄ%mul_2417 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%hardsigmoid_6, %hardswish_12), kwargs = {})Jr
pkg.torch.onnx.name_scopesT['', 'features', 'features.9', 'features.9.block', 'features.9.block.2', 'mul_2417']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Ø
mul_2417
features.9.block.3.0.weight
 features.9.block.3.0.weight_bias
getitem_78node_Conv_489"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J£
	namespaceï: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.9: torchvision.models.mobilenetv3.InvertedResidual/features.9.block: torch.nn.modules.container.Sequential/features.9.block.3: torchvision.ops.misc.Conv2dNormActivation/features.9.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_26: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_26 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_40, %p_features_9_block_3_1_weight, %p_features_9_block_3_1_bias, %b_features_9_block_3_1_running_mean, %b_features_9_block_3_1_running_var, 0.01, 0.001), kwargs = {})J™
pkg.torch.onnx.name_scopesã['', 'features', 'features.9', 'features.9.block', 'features.9.block.3', 'features.9.block.3.1', '_native_batch_norm_legit_no_training_26']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ø

getitem_78
features.10.block.0.0.weight
!features.10.block.0.0.weight_bias
getitem_81node_Conv_491"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†Jß
	namespaceô: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.0: torchvision.ops.misc.Conv2dNormActivation/features.10.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_27: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J„
pkg.torch.onnx.fx_node»%_native_batch_norm_legit_no_training_27 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_41, %p_features_10_block_0_1_weight, %p_features_10_block_0_1_bias, %b_features_10_block_0_1_running_mean, %b_features_10_block_0_1_running_var, 0.01, 0.001), kwargs = {})JÆ
pkg.torch.onnx.name_scopesè['', 'features', 'features.10', 'features.10.block', 'features.10.block.0', 'features.10.block.0.1', '_native_batch_norm_legit_no_training_27']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ù

getitem_81hardswish_13n0_14"	HardSwishJ
	namespace‚: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.0: torchvision.ops.misc.Conv2dNormActivation/features.10.block.0.2: torch.nn.modules.activation.Hardswish/hardswish_13: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jî
pkg.torch.onnx.fx_nodez%hardswish_13 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_81,), kwargs = {})Jí
pkg.torch.onnx.name_scopest['', 'features', 'features.10', 'features.10.block', 'features.10.block.0', 'features.10.block.0.2', 'hardswish_13']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
¬
hardswish_13
features.10.block.1.0.weight
!features.10.block.1.0.weight_bias
getitem_84node_Conv_493"Conv*
group¿†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†Jß
	namespaceô: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.1: torchvision.ops.misc.Conv2dNormActivation/features.10.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_28: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J„
pkg.torch.onnx.fx_node»%_native_batch_norm_legit_no_training_28 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_42, %p_features_10_block_1_1_weight, %p_features_10_block_1_1_bias, %b_features_10_block_1_1_running_mean, %b_features_10_block_1_1_running_var, 0.01, 0.001), kwargs = {})JÆ
pkg.torch.onnx.name_scopesè['', 'features', 'features.10', 'features.10.block', 'features.10.block.1', 'features.10.block.1.1', '_native_batch_norm_legit_no_training_28']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ù

getitem_84hardswish_14n0_15"	HardSwishJ
	namespace‚: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.1: torchvision.ops.misc.Conv2dNormActivation/features.10.block.1.2: torch.nn.modules.activation.Hardswish/hardswish_14: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jî
pkg.torch.onnx.fx_nodez%hardswish_14 : [num_users=2] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_84,), kwargs = {})Jí
pkg.torch.onnx.name_scopest['', 'features', 'features.10', 'features.10.block', 'features.10.block.1', 'features.10.block.1.2', 'hardswish_14']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
’
hardswish_14
val_23mean_7node_mean_7"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÈ
	namespace€: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.2: torchvision.ops.misc.SqueezeExcitation/features.10.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_7: aten.mean.dimJÆ
pkg.torch.onnx.class_hierarchyã['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jñ
pkg.torch.onnx.fx_node|%mean_7 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%hardswish_14, [-1, -2], True), kwargs = {})Jí
pkg.torch.onnx.name_scopest['', 'features', 'features.10', 'features.10.block', 'features.10.block.2', 'features.10.block.2.avgpool', 'mean_7']J¢	
pkg.torch.onnx.stack_traceÉ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
⁄
mean_7
features.10.block.2.fc1.weight
features.10.block.2.fc1.bias	conv2d_43node_conv2d_43"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‡
	namespace“: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.2: torchvision.ops.misc.SqueezeExcitation/features.10.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_43: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JŒ
pkg.torch.onnx.fx_node≥%conv2d_43 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_7, %p_features_10_block_2_fc1_weight, %p_features_10_block_2_fc1_bias), kwargs = {})Jë
pkg.torch.onnx.name_scopess['', 'features', 'features.10', 'features.10.block', 'features.10.block.2', 'features.10.block.2.fc1', 'conv2d_43']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
˛
	conv2d_43relu_12node_relu_12"ReluJÁ
	namespaceŸ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.2: torchvision.ops.misc.SqueezeExcitation/features.10.block.2.activation: torch.nn.modules.activation.ReLU/relu_12: aten.relu.defaultJ®
pkg.torch.onnx.class_hierarchyÖ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jâ
pkg.torch.onnx.fx_nodeo%relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%conv2d_43,), kwargs = {})Jñ
pkg.torch.onnx.name_scopesx['', 'features', 'features.10', 'features.10.block', 'features.10.block.2', 'features.10.block.2.activation', 'relu_12']Jô	
pkg.torch.onnx.stack_trace˙File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
‹
relu_12
features.10.block.2.fc2.weight
features.10.block.2.fc2.bias	conv2d_44node_conv2d_44"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‡
	namespace“: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.2: torchvision.ops.misc.SqueezeExcitation/features.10.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_44: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jœ
pkg.torch.onnx.fx_node¥%conv2d_44 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_12, %p_features_10_block_2_fc2_weight, %p_features_10_block_2_fc2_bias), kwargs = {})Jë
pkg.torch.onnx.name_scopess['', 'features', 'features.10', 'features.10.block', 'features.10.block.2', 'features.10.block.2.fc2', 'conv2d_44']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Û
	conv2d_44hardsigmoid_7node_hardsigmoid_7"HardSigmoid*
beta   ?†*
alpha´™*>†JÅ
	namespaceÛ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.2: torchvision.ops.misc.SqueezeExcitation/features.10.block.2.scale_activation: torch.nn.modules.activation.Hardsigmoid/hardsigmoid_7: aten.hardsigmoid.defaultJ∂
pkg.torch.onnx.class_hierarchyì['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Hardsigmoid', 'aten.hardsigmoid.default']Jñ
pkg.torch.onnx.fx_node|%hardsigmoid_7 : [num_users=1] = call_function[target=torch.ops.aten.hardsigmoid.default](args = (%conv2d_44,), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'features', 'features.10', 'features.10.block', 'features.10.block.2', 'features.10.block.2.scale_activation', 'hardsigmoid_7']Jò	
pkg.torch.onnx.stack_trace˘File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 402, in forward
    return F.hardsigmoid(input, self.inplace)
ø
hardsigmoid_7
hardswish_14mul_2731node_mul_2731"MulJ•
	namespaceó: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2731: aten.mul.TensorJÇ
pkg.torch.onnx.class_hierarchyﬂ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jõ
pkg.torch.onnx.fx_nodeÄ%mul_2731 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%hardsigmoid_7, %hardswish_14), kwargs = {})Ju
pkg.torch.onnx.name_scopesW['', 'features', 'features.10', 'features.10.block', 'features.10.block.2', 'mul_2731']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Ω
mul_2731
features.10.block.3.0.weight
!features.10.block.3.0.weight_bias
getitem_87node_Conv_495"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†Jß
	namespaceô: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/features.10.block: torch.nn.modules.container.Sequential/features.10.block.3: torchvision.ops.misc.Conv2dNormActivation/features.10.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_29: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J„
pkg.torch.onnx.fx_node»%_native_batch_norm_legit_no_training_29 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_45, %p_features_10_block_3_1_weight, %p_features_10_block_3_1_bias, %b_features_10_block_3_1_running_mean, %b_features_10_block_3_1_running_var, 0.01, 0.001), kwargs = {})JÆ
pkg.torch.onnx.name_scopesè['', 'features', 'features.10', 'features.10.block', 'features.10.block.3', 'features.10.block.3.1', '_native_batch_norm_legit_no_training_29']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
¿	

getitem_87

getitem_78add_1017node_add_1017"AddJ∞
	namespace¢: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.10: torchvision.models.mobilenetv3.InvertedResidual/add_1017: aten.add.TensorJØ
pkg.torch.onnx.class_hierarchyå['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'aten.add.Tensor']Jï
pkg.torch.onnx.fx_node{%add_1017 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_87, %getitem_78), kwargs = {})JI
pkg.torch.onnx.name_scopes+['', 'features', 'features.10', 'add_1017']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 114, in forward
    result += input
Ω
add_1017
features.11.block.0.0.weight
!features.11.block.0.0.weight_bias
getitem_90node_Conv_497"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†Jß
	namespaceô: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.0: torchvision.ops.misc.Conv2dNormActivation/features.11.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_30: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J„
pkg.torch.onnx.fx_node»%_native_batch_norm_legit_no_training_30 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_46, %p_features_11_block_0_1_weight, %p_features_11_block_0_1_bias, %b_features_11_block_0_1_running_mean, %b_features_11_block_0_1_running_var, 0.01, 0.001), kwargs = {})JÆ
pkg.torch.onnx.name_scopesè['', 'features', 'features.11', 'features.11.block', 'features.11.block.0', 'features.11.block.0.1', '_native_batch_norm_legit_no_training_30']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ù

getitem_90hardswish_15n0_16"	HardSwishJ
	namespace‚: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.0: torchvision.ops.misc.Conv2dNormActivation/features.11.block.0.2: torch.nn.modules.activation.Hardswish/hardswish_15: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jî
pkg.torch.onnx.fx_nodez%hardswish_15 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_90,), kwargs = {})Jí
pkg.torch.onnx.name_scopest['', 'features', 'features.11', 'features.11.block', 'features.11.block.0', 'features.11.block.0.2', 'hardswish_15']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
¬
hardswish_15
features.11.block.1.0.weight
!features.11.block.1.0.weight_bias
getitem_93node_Conv_499"Conv*
group¿†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†Jß
	namespaceô: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.1: torchvision.ops.misc.Conv2dNormActivation/features.11.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_31: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J„
pkg.torch.onnx.fx_node»%_native_batch_norm_legit_no_training_31 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_47, %p_features_11_block_1_1_weight, %p_features_11_block_1_1_bias, %b_features_11_block_1_1_running_mean, %b_features_11_block_1_1_running_var, 0.01, 0.001), kwargs = {})JÆ
pkg.torch.onnx.name_scopesè['', 'features', 'features.11', 'features.11.block', 'features.11.block.1', 'features.11.block.1.1', '_native_batch_norm_legit_no_training_31']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
ù

getitem_93hardswish_16n0_17"	HardSwishJ
	namespace‚: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.1: torchvision.ops.misc.Conv2dNormActivation/features.11.block.1.2: torch.nn.modules.activation.Hardswish/hardswish_16: aten.hardswish.defaultJµ
pkg.torch.onnx.class_hierarchyí['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jî
pkg.torch.onnx.fx_nodez%hardswish_16 : [num_users=2] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_93,), kwargs = {})Jí
pkg.torch.onnx.name_scopest['', 'features', 'features.11', 'features.11.block', 'features.11.block.1', 'features.11.block.1.2', 'hardswish_16']Jó	
pkg.torch.onnx.stack_trace¯File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
’
hardswish_16
val_23mean_8node_mean_8"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÈ
	namespace€: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.2: torchvision.ops.misc.SqueezeExcitation/features.11.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_8: aten.mean.dimJÆ
pkg.torch.onnx.class_hierarchyã['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jñ
pkg.torch.onnx.fx_node|%mean_8 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%hardswish_16, [-1, -2], True), kwargs = {})Jí
pkg.torch.onnx.name_scopest['', 'features', 'features.11', 'features.11.block', 'features.11.block.2', 'features.11.block.2.avgpool', 'mean_8']J¢	
pkg.torch.onnx.stack_traceÉ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
⁄
mean_8
features.11.block.2.fc1.weight
features.11.block.2.fc1.bias	conv2d_48node_conv2d_48"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‡
	namespace“: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.2: torchvision.ops.misc.SqueezeExcitation/features.11.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_48: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JŒ
pkg.torch.onnx.fx_node≥%conv2d_48 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_8, %p_features_11_block_2_fc1_weight, %p_features_11_block_2_fc1_bias), kwargs = {})Jë
pkg.torch.onnx.name_scopess['', 'features', 'features.11', 'features.11.block', 'features.11.block.2', 'features.11.block.2.fc1', 'conv2d_48']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
˛
	conv2d_48relu_13node_relu_13"ReluJÁ
	namespaceŸ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.2: torchvision.ops.misc.SqueezeExcitation/features.11.block.2.activation: torch.nn.modules.activation.ReLU/relu_13: aten.relu.defaultJ®
pkg.torch.onnx.class_hierarchyÖ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jâ
pkg.torch.onnx.fx_nodeo%relu_13 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%conv2d_48,), kwargs = {})Jñ
pkg.torch.onnx.name_scopesx['', 'features', 'features.11', 'features.11.block', 'features.11.block.2', 'features.11.block.2.activation', 'relu_13']Jô	
pkg.torch.onnx.stack_trace˙File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
‹
relu_13
features.11.block.2.fc2.weight
features.11.block.2.fc2.bias	conv2d_49node_conv2d_49"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J‡
	namespace“: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.2: torchvision.ops.misc.SqueezeExcitation/features.11.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_49: aten.conv2d.defaultJ¶
pkg.torch.onnx.class_hierarchyÉ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jœ
pkg.torch.onnx.fx_node¥%conv2d_49 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_13, %p_features_11_block_2_fc2_weight, %p_features_11_block_2_fc2_bias), kwargs = {})Jë
pkg.torch.onnx.name_scopess['', 'features', 'features.11', 'features.11.block', 'features.11.block.2', 'features.11.block.2.fc2', 'conv2d_49']J°	
pkg.torch.onnx.stack_traceÇ	File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
Û
	conv2d_49hardsigmoid_8node_hardsigmoid_8"HardSigmoid*
beta   ?†*
alpha´™*>†JÅ
	namespaceÛ: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.2: torchvision.ops.misc.SqueezeExcitation/features.11.block.2.scale_activation: torch.nn.modules.activation.Hardsigmoid/hardsigmoid_8: aten.hardsigmoid.defaultJ∂
pkg.torch.onnx.class_hierarchyì['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Hardsigmoid', 'aten.hardsigmoid.default']Jñ
pkg.torch.onnx.fx_node|%hardsigmoid_8 : [num_users=1] = call_function[target=torch.ops.aten.hardsigmoid.default](args = (%conv2d_49,), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'features', 'features.11', 'features.11.block', 'features.11.block.2', 'features.11.block.2.scale_activation', 'hardsigmoid_8']Jò	
pkg.torch.onnx.stack_trace˘File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 402, in forward
    return F.hardsigmoid(input, self.inplace)
ø
hardsigmoid_8
hardswish_16mul_3057node_mul_3057"MulJ•
	namespaceó: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.2: torchvision.ops.misc.SqueezeExcitation/mul_3057: aten.mul.TensorJÇ
pkg.torch.onnx.class_hierarchyﬂ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jõ
pkg.torch.onnx.fx_nodeÄ%mul_3057 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%hardsigmoid_8, %hardswish_16), kwargs = {})Ju
pkg.torch.onnx.name_scopesW['', 'features', 'features.11', 'features.11.block', 'features.11.block.2', 'mul_3057']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Ω
mul_3057
features.11.block.3.0.weight
!features.11.block.3.0.weight_bias
getitem_96node_Conv_501"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†Jß
	namespaceô: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/features.11.block: torch.nn.modules.container.Sequential/features.11.block.3: torchvision.ops.misc.Conv2dNormActivation/features.11.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_32: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJ—
pkg.torch.onnx.class_hierarchyÆ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J„
pkg.torch.onnx.fx_node»%_native_batch_norm_legit_no_training_32 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_50, %p_features_11_block_3_1_weight, %p_features_11_block_3_1_bias, %b_features_11_block_3_1_running_mean, %b_features_11_block_3_1_running_var, 0.01, 0.001), kwargs = {})JÆ
pkg.torch.onnx.name_scopesè['', 'features', 'features.11', 'features.11.block', 'features.11.block.3', 'features.11.block.3.1', '_native_batch_norm_legit_no_training_32']JÉ	
pkg.torch.onnx.stack_trace‰File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 112, in forward
    result = self.block(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
º	

getitem_96
add_1017add_1096node_add_1096"AddJ∞
	namespace¢: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.11: torchvision.models.mobilenetv3.InvertedResidual/add_1096: aten.add.TensorJØ
pkg.torch.onnx.class_hierarchyå['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.models.mobilenetv3.InvertedResidual', 'aten.add.Tensor']Jì
pkg.torch.onnx.fx_nodey%add_1096 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_96, %add_1017), kwargs = {})JI
pkg.torch.onnx.name_scopes+['', 'features', 'features.11', 'add_1096']Jø
pkg.torch.onnx.stack_trace†File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py", line 114, in forward
    result += input

add_1096
features.12.0.weight
features.12.0.weight_bias
getitem_99node_Conv_503"Conv*
group†*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J°
	namespaceì: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.12: torchvision.ops.misc.Conv2dNormActivation/features.12.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_33: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJı
pkg.torch.onnx.class_hierarchy“['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J√
pkg.torch.onnx.fx_node®%_native_batch_norm_legit_no_training_33 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_51, %p_features_12_1_weight, %p_features_12_1_bias, %b_features_12_1_running_mean, %b_features_12_1_running_var, 0.01, 0.001), kwargs = {})Jy
pkg.torch.onnx.name_scopes[['', 'features', 'features.12', 'features.12.1', '_native_batch_norm_legit_no_training_33']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
Å

getitem_99hardswish_17n0_18"	HardSwishJÍ
	namespace‹: __main__.MobileNetV3Audio/features: torch.nn.modules.container.Sequential/features.12: torchvision.ops.misc.Conv2dNormActivation/features.12.2: torch.nn.modules.activation.Hardswish/hardswish_17: aten.hardswish.defaultJŸ
pkg.torch.onnx.class_hierarchy∂['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jî
pkg.torch.onnx.fx_nodez%hardswish_17 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%getitem_99,), kwargs = {})J^
pkg.torch.onnx.name_scopes@['', 'features', 'features.12', 'features.12.2', 'hardswish_17']Jí
pkg.torch.onnx.stack_traceÛFile "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 49, in forward
    x = self.features(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
œ
hardswish_17
val_23mean_9node_mean_9"
ReduceMean*
noop_with_empty_axes †*
keepdims†Jr
	namespacee: __main__.MobileNetV3Audio/avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_9: aten.mean.dimJ~
pkg.torch.onnx.class_hierarchy\['__main__.MobileNetV3Audio', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jñ
pkg.torch.onnx.fx_node|%mean_9 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%hardswish_17, [-1, -2], True), kwargs = {})J7
pkg.torch.onnx.name_scopes['', 'avgpool', 'mean_9']J°
pkg.torch.onnx.stack_traceÇFile "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 50, in forward
    x = self.avgpool(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py", line 1500, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
€
mean_9
val_333view	node_view"Reshape*
	allowzero†J@
	namespace3: __main__.MobileNetV3Audio/view: aten.view.defaultJT
pkg.torch.onnx.class_hierarchy2['__main__.MobileNetV3Audio', 'aten.view.default']Jå
pkg.torch.onnx.fx_noder%view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mean_9, [1, 576]), kwargs = {})J*
pkg.torch.onnx.name_scopes['', 'view']J»
pkg.torch.onnx.stack_trace©File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 51, in forward
    x = torch.flatten(x, 1)
±

view
classifier.0.weight
classifier.0.biaslinearnode_linear"Gemm*
beta  Ä?†*
transB†*
alpha  Ä?†*
transA †J§
	namespaceñ: __main__.MobileNetV3Audio/classifier: torch.nn.modules.container.Sequential/classifier.0: torch.nn.modules.linear.Linear/linear: aten.linear.defaultJ°
pkg.torch.onnx.class_hierarchy['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J≥
pkg.torch.onnx.fx_nodeò%linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%view, %p_classifier_0_weight, %p_classifier_0_bias), kwargs = {})JJ
pkg.torch.onnx.name_scopes,['', 'classifier', 'classifier.0', 'linear']JŸ
pkg.torch.onnx.stack_trace∫File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 52, in forward
    x = self.classifier(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ã	
linearhardswish_18n0_19"	HardSwishJ¥
	namespace¶: __main__.MobileNetV3Audio/classifier: torch.nn.modules.container.Sequential/classifier.1: torch.nn.modules.activation.Hardswish/hardswish_18: aten.hardswish.defaultJ¨
pkg.torch.onnx.class_hierarchyâ['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.activation.Hardswish', 'aten.hardswish.default']Jê
pkg.torch.onnx.fx_nodev%hardswish_18 : [num_users=1] = call_function[target=torch.ops.aten.hardswish.default](args = (%linear,), kwargs = {})JP
pkg.torch.onnx.name_scopes2['', 'classifier', 'classifier.1', 'hardswish_18']J÷
pkg.torch.onnx.stack_trace∑File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 52, in forward
    x = self.classifier(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 570, in forward
    return F.hardswish(input, self.inplace)
¬

hardswish_18
classifier.3.weight
classifier.3.biaslogitsnode_linear_1"Gemm*
beta  Ä?†*
transB†*
alpha  Ä?†*
transA †J¶
	namespaceò: __main__.MobileNetV3Audio/classifier: torch.nn.modules.container.Sequential/classifier.3: torch.nn.modules.linear.Linear/linear_1: aten.linear.defaultJ°
pkg.torch.onnx.class_hierarchy['__main__.MobileNetV3Audio', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J∂
pkg.torch.onnx.fx_nodeõ%linear_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone, %p_classifier_3_weight, %p_classifier_3_bias), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'classifier', 'classifier.3', 'linear_1']JŸ
pkg.torch.onnx.stack_trace∫File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/Training/SubSampledTrackNew/export_to_onnx.py", line 52, in forward
    x = self.classifier(x)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/q490916/Documents/Development/ZwitscherkastenTransformerTrack/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
main_graph*cBfeatures.0.0.weightj!
locationmodel_audio.onnx.dataj
offset6848j
length576p*kBfeatures.1.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset7424j
length576p*mBfeatures.1.block.1.fc1.weightj!
locationmodel_audio.onnx.dataj
offset5312j
length512p*CBfeatures.1.block.1.fc1.biasJ Z%ΩΩÔàΩ˛C?æ        Ùê⁄Ω¢/>Ùº*mBfeatures.1.block.1.fc2.weightj!
locationmodel_audio.onnx.dataj
offset5824j
length512p*cBfeatures.1.block.1.fc2.biasJ@]\ÙΩZ- ææX˙=¸‰*æÙEΩ‹dá>H‘º¨®<Ó”?æ˝|ó=ŒÕI>∞C'ª ‚.º·I–>≥rb>+8æ*mBfeatures.1.block.2.0.weightj!
locationmodel_audio.onnx.dataj
offset16640j
length1024p*mHBfeatures.2.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset47104j
length4608p*mHBfeatures.2.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset37248j
length2592p*mHBfeatures.2.block.2.0.weightj!
locationmodel_audio.onnx.dataj
offset51712j
length6912p*mXBfeatures.3.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset58624j
length8448p*mXBfeatures.3.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset39840j
length3168p*mXBfeatures.3.block.2.0.weightj!
locationmodel_audio.onnx.dataj
offset67072j
length8448p*m`Bfeatures.4.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset75520j
length9216p*n`Bfeatures.4.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset103168j
length9600p*o`Bfeatures.4.block.2.fc1.weightj!
locationmodel_audio.onnx.dataj
offset84736j
length9216p*ÉBfeatures.4.block.2.fc1.biasJ`<ã=è©;>ß”>”ç”º’5/Ω=çæOÄ˚=ÁÍΩÍçº}x*>${´<≥…<Ûâ`>·®.=v œΩ¯Q;>Ú´ΩHö>-›ÇΩÏ‘ΩÉ >∑´ºK∂»<ÁÂ=*o`Bfeatures.4.block.2.fc2.weightj!
locationmodel_audio.onnx.dataj
offset93952j
length9216p*e`Bfeatures.4.block.2.fc2.biasj!
locationmodel_audio.onnx.dataj
offset1568j
length384p*o(`Bfeatures.4.block.3.0.weightj!
locationmodel_audio.onnx.dataj
offset139168j
length15360p*p(Bfeatures.5.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset405664j
length38400p*pBfeatures.5.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset273568j
length24000p*r@Bfeatures.5.block.2.fc1.weightj!
locationmodel_audio.onnx.dataj
offset729760j
length61440p*§@Bfeatures.5.block.2.fc1.biasJÄ¥föºR/
>!SƒΩ@ó∂=*}Ω=ƒ+=+¡>æú∞é<◊ÓêΩ√{\º∏/ã=÷«Læ©`˚Ω0Ä(æy>Ø‡û=J2>=œÀ>ó≈<˛çà=E¢Ω:ú»=‹§ã∫ı*é=é|Àº◊éº¸~=Á†=IF∞=w«èΩ˜€ºAé1ΩT4'=•öΩÊË›º5ÕK=†ËAΩ°ã6ºÑ+Ω÷óæ#ëq=K§æÛîÊªÔ=/XΩÚÅΩb¡>USHºıÀ1æ¡6æsµΩ∫êK=7≥Ã;å∫ΩΩ√Éü=ëCéºUëΩÎ≥äΩ£©:æï‚ΩÆ√¨=©∏ÀΩÚfrΩu%≠º*r@Bfeatures.5.block.2.fc2.weightj!
locationmodel_audio.onnx.dataj
offset791200j
length61440p*gBfeatures.5.block.2.fc2.biasj!
locationmodel_audio.onnx.dataj
offset10880j
length960p*p(Bfeatures.5.block.3.0.weightj!
locationmodel_audio.onnx.dataj
offset444064j
length38400p*p(Bfeatures.6.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset482464j
length38400p*pBfeatures.6.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset297568j
length24000p*r@Bfeatures.6.block.2.fc1.weightj!
locationmodel_audio.onnx.dataj
offset852640j
length61440p*§@Bfeatures.6.block.2.fc1.biasJÄìeìΩ˘9À=ÌAæ{h!æRqCΩM¶R=¸B,æΩà‡ΩdüÀ=*ìæª’ºı;æ)º=3¢ªOIfæ9˛¡Ω[='Ω ;Ú< 
ÇΩº'õΩ®?K=w_ﬁ=Û≤÷Ω9è∏ΩDó‡=Rüæ"˝˝<üÉº î¨=ç±Z<-f™ª∆œªıZª=C≠(æR˛>eÈ¢=˚È =ÿà∞=y#F9a‡;Y€4ºïeäΩ&ﬁ–Ω†É=WçÁºF√=◊ﬂÃºÏcæ‘ëHæoæø$â=µΩª˚æ^≠ =0µdºÖÒ;Ä1 <;Õ
>#HΩ;Œ;{Mæ6Ω*–Ωù›VΩ*r@Bfeatures.6.block.2.fc2.weightj!
locationmodel_audio.onnx.dataj
offset914080j
length61440p*gBfeatures.6.block.2.fc2.biasj!
locationmodel_audio.onnx.dataj
offset11840j
length960p*p(Bfeatures.6.block.3.0.weightj!
locationmodel_audio.onnx.dataj
offset520864j
length38400p*ox(Bfeatures.7.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset185248j
length19200p*oxBfeatures.7.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset112768j
length12000p*q xBfeatures.7.block.2.fc1.weightj!
locationmodel_audio.onnx.dataj
offset154528j
length15360p*§ Bfeatures.7.block.2.fc1.biasJÄØ¿L=/fÀΩºüå=ÌVΩ⁄†=∆ LºV,W>öƒ\Ω∑00=__~=πUÄ=Á(Â;˜˝`<?ÙΩæ∞%ª£à÷Ω,|
=dÆ	>õWΩ}∑ê∫[	ΩØ´>∞A~<E&≠ΩuœáºÍøçºåÛ$>˜YΩcÛ>N=¯ΩA ö=*qx Bfeatures.7.block.2.fc2.weightj!
locationmodel_audio.onnx.dataj
offset169888j
length15360p*exBfeatures.7.block.2.fc2.biasj!
locationmodel_audio.onnx.dataj
offset3872j
length480p*o0xBfeatures.7.block.3.0.weightj!
locationmodel_audio.onnx.dataj
offset204448j
length23040p*pê0Bfeatures.8.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset321568j
length27648p*pêBfeatures.8.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset124768j
length14400p*r(êBfeatures.8.block.2.fc1.weightj!
locationmodel_audio.onnx.dataj
offset227488j
length23040p*ƒ(Bfeatures.8.block.2.fc1.biasJ†´k;æs,óº“Îì=˛åA=ﬁ≠÷=øËºÎC™<˘ûm:vòΩ“;ô=U∂>^ö◊º#Û=+F<ôá<yæ	PÅ;8.>TÁ;Z>N\>ÍÏ+=}~Ó=Tâ7æë8∫=J/ä=>_>ø∂•=U?>É˜£Ω‘Ã=q>æìmÓ:zÍ:¸‘∑<ä%c=-oœº3P∏Ω¬û~º≥>*rê(Bfeatures.8.block.2.fc2.weightj!
locationmodel_audio.onnx.dataj
offset250528j
length23040p*fêBfeatures.8.block.2.fc2.biasj!
locationmodel_audio.onnx.dataj
offset8000j
length576p*p0êBfeatures.8.block.3.0.weightj!
locationmodel_audio.onnx.dataj
offset349216j
length27648p*p†0Bfeatures.9.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset559264j
length55296p*p†Bfeatures.9.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset376864j
length28800p*rH†Bfeatures.9.block.2.fc1.weightj!
locationmodel_audio.onnx.dataj
offset975520j
length82944p*bHBfeatures.9.block.2.fc1.biasj!
locationmodel_audio.onnx.dataj
offset0j
length288p*s†HBfeatures.9.block.2.fc2.weightj!
locationmodel_audio.onnx.dataj
offset1058464j
length82944p*h†Bfeatures.9.block.2.fc2.biasj!
locationmodel_audio.onnx.dataj
offset17664j
length1152p*r`†Bfeatures.9.block.3.0.weightj!
locationmodel_audio.onnx.dataj
offset1141408j
length110592p*s¿`Bfeatures.10.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset1252000j
length221184p*q¿Bfeatures.10.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset614560j
length57600p*vê¿Bfeatures.10.block.2.fc1.weightj!
locationmodel_audio.onnx.dataj
offset2357920j
length331776p*gêBfeatures.10.block.2.fc1.biasj!
locationmodel_audio.onnx.dataj
offset8576j
length576p*v¿êBfeatures.10.block.2.fc2.weightj!
locationmodel_audio.onnx.dataj
offset2689696j
length331776p*i¿Bfeatures.10.block.2.fc2.biasj!
locationmodel_audio.onnx.dataj
offset21120j
length2304p*s`¿Bfeatures.10.block.3.0.weightj!
locationmodel_audio.onnx.dataj
offset1473184j
length221184p*s¿`Bfeatures.11.block.0.0.weightj!
locationmodel_audio.onnx.dataj
offset1694368j
length221184p*q¿Bfeatures.11.block.1.0.weightj!
locationmodel_audio.onnx.dataj
offset672160j
length57600p*vê¿Bfeatures.11.block.2.fc1.weightj!
locationmodel_audio.onnx.dataj
offset3021472j
length331776p*gêBfeatures.11.block.2.fc1.biasj!
locationmodel_audio.onnx.dataj
offset9152j
length576p*v¿êBfeatures.11.block.2.fc2.weightj!
locationmodel_audio.onnx.dataj
offset3353248j
length331776p*i¿Bfeatures.11.block.2.fc2.biasj!
locationmodel_audio.onnx.dataj
offset23424j
length2304p*s`¿Bfeatures.11.block.3.0.weightj!
locationmodel_audio.onnx.dataj
offset1915552j
length221184p*k¿`Bfeatures.12.0.weightj!
locationmodel_audio.onnx.dataj
offset2136736j
length221184p*hÄ¿Bclassifier.0.weightj!
locationmodel_audio.onnx.dataj
offset4259840j
length2359296p*^ÄBclassifier.0.biasj!
locationmodel_audio.onnx.dataj
offset43008j
length4096p*gÄÄBclassifier.3.weightj!
locationmodel_audio.onnx.dataj
offset3685024j
length524288p*\ÄBclassifier.3.biasj!
locationmodel_audio.onnx.dataj
offset6336j
length512p*Bval_23Jˇˇˇˇˇˇˇˇ˛ˇˇˇˇˇˇˇ*Bval_333J       @      *`Bfeatures.0.0.weight_biasJ@9÷øPI∑øòΩπøJ]hø,Nı=z≥e?4m?= ãø.h®øƒ;|æ )§ø\*®øÇ¿øò˛´=Ù˝√øó‰Ûø*hB features.1.block.0.0.weight_biasJ@Ré>™lærôìæF9°æ“¡æ≤—‘æ¶8?‰	—Ω¬”N?ñXeø9√∂?D›?›Fº?P‘?[˝§?Fb´>*hB features.1.block.2.0.weight_biasJ@Û‚æòn©>E?\Jí?«e˘æaË£?¸Fæ(¨røé?æÓl˙?ÁÇVæÄA_;J~øæoøNÈ·æ7{ =*iHB features.2.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset288j
length288p*iHB features.2.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset576j
length288p*àB features.2.block.2.0.weight_biasJ`J‘ø¿0;î…ø1ˇ[øÉoæ¯º¬@âøπCØ>àw˛>uéj>‘˛:æ[ûø¬˙øTÚb?ˆ•XΩØÉ«Ω 2É9¢!ø1: ?ÑzÑ=¶®éøﬁU?lÃ˘='°"æ*iXB features.3.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset864j
length352p*jXB features.3.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset1216j
length352p*àB features.3.block.2.0.weight_biasJ` ûZ;ÿ*gøÿˆ«æxû	?ÙÉÊ=≥-∑>|¢ïæjM?Z<'æ®bøÊ)Fæd$“Ω±~≥æ¥6¡æÜløﬂÒ•?ˆ$YølB>≈B^?â‹?Û)æH√˘æ4©ó>ÇcÛ?*j`B features.4.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset1952j
length384p*j`B features.4.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset2336j
length384p*…(B features.4.block.3.0.weight_biasJ†L™s>qAø∏˚◊=%û¡æå9®ævÆ‘>éôùæ¢>xNÌæÄ+/;D‡!=#¨ƒæ|´?÷€Tø®ƒ>Ys=æÖ>ö^>WY˚>n'>»;…Ωâπó>yZ=tpgø‘-ÅΩ-eæA˙ßæ√?ô>Ó:?¨DøIÿ[æu‰#>€Œ ø∑>>z7Ÿ=Í=>òk9æ4G:>!„»=IÆ;>*lB features.5.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset12800j
length960p*lB features.5.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset13760j
length960p*…(B features.5.block.3.0.weight_biasJ†H$·æ†v=LÈΩê[.=µ…x>™æ$ê-=hõæ{TØ=aM>ï?∞æŸ∫◊Ω≤¡I>x'ÅΩf°ã>¢ÚàæƒÑÇ=∏Dì=h	ÒΩÇ#U>Lèb>â¶Ω™¬§æbeæÂ!‰=ônë>⁄º@vºÚÅS>V∑û=∏B>Ω^æA|xæ@(A<P{Ä>≈Ç>˙¨≥>\>≈Ω";ê>.Çhº*lB features.6.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset14720j
length960p*lB features.6.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset15680j
length960p*…(B features.6.block.3.0.weight_biasJ†|	ÓæcßHæ~æ√q> µÎºVßIΩ‰òﬂæ[Mï=º‚ÅΩÜΩi>ÇBæâ–Ã<oΩÕΩ>ﬁº¨>˙øÚòV=Fè{>Ω∞ã<÷dÇ>Î• ΩÄñÜ:_˜)æ0ƒ˝æRPôæ–	=> âæˇÄΩ®Vxº2Ùåæ	™ÅΩ&ÜÎΩ@Y«Ω
9‰<†iº>_‰∂Ω~êGæmeöæ,’∆>¿»ä=*jxB features.7.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset4352j
length480p*jxB features.7.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset4832j
length480p*È0B features.7.block.3.0.weight_biasJ¿ëBh>V>&è•>gAæ’ãÎΩÙ·°Ω 2¨<{ø¿Ö >8#™Ω<∆>à^iæ|°æƒ>0^læ–ö8ºø¸c>Ü"=·≥0æO@>(u>≤
~æ|@3Ω]v∆=†Î6æ†Ñ=∂«>âoæÉæ‘˘üº*n/>ŒU>[˛=HÃêæznnæPTºº⁄`æÙ|Q>∞ào<¨ˇ>¥9e<¬X_æsMçæ§á©>ítæÚ>@òˇ:*kêB features.8.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset9728j
length576p*lêB features.8.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset10304j
length576p*È0B features.8.block.3.0.weight_biasJ¿ﬁë>‚ï»=™Ñ_>Çh÷=´ÿ`Ωøñéæ 'Æ>$„æ|>Ñ∂∆=‚Ô=¥ìèæƒŸΩæh‚J>‰üΩ ã§;+ﬁ◊æ≠—áΩÑ	úΩó =s>6	=Y)æ%l⁄=Hrü<«åﬂæP«á<h‚æ2*Ω¨YÊΩn5Ñ=¿‡'=∂B\æˆæÔ=Ÿyæö˛
>≤›¿< ≥ü∫¨””>“¯¢=H’=>ÖƒÅæhæêæN7=L>æ“æˆ∂º˛´Ω*m†B features.9.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset18816j
length1152p*m†B features.9.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset19968j
length1152p*j`B features.9.block.3.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset2720j
length384p*n¿B!features.10.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset25728j
length2304p*n¿B!features.10.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset28032j
length2304p*k`B!features.10.block.3.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset3104j
length384p*n¿B!features.11.block.0.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset30336j
length2304p*n¿B!features.11.block.1.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset32640j
length2304p*k`B!features.11.block.3.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset3488j
length384p*f¿Bfeatures.12.0.weight_biasj!
locationmodel_audio.onnx.dataj
offset34944j
length2304pZ’
mel_spectrogram

s77

Ä
s0"=
/pkg.torch.export.graph_signature.InputSpec.kind
USER_INPUT"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"&
!pkg.torch.onnx.original_node_namexbâ
logits
	

Ä"?
0pkg.torch.export.graph_signature.OutputSpec.kindUSER_OUTPUT"-
!pkg.torch.onnx.original_node_namelinear_1j-
features.0.0.weight




j5
features.1.block.0.0.weight




j˙
features.1.block.1.fc1.weight




"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_1_block_1_fc1_weightjÍ
features.1.block.1.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_1_block_1_fc1_biasj˙
features.1.block.1.fc2.weight




"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_1_block_1_fc2_weightjÍ
features.1.block.1.fc2.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_1_block_1_fc2_biasj5
features.1.block.2.0.weight




j5
features.2.block.0.0.weight

H


j5
features.2.block.1.0.weight

H


j5
features.2.block.2.0.weight


H

j5
features.3.block.0.0.weight

X


j5
features.3.block.1.0.weight

X


j5
features.3.block.2.0.weight


X

j5
features.4.block.0.0.weight

`


j5
features.4.block.1.0.weight

`


j˙
features.4.block.2.fc1.weight


`

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_4_block_2_fc1_weightjÍ
features.4.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_4_block_2_fc1_biasj˙
features.4.block.2.fc2.weight

`


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_4_block_2_fc2_weightjÍ
features.4.block.2.fc2.bias


`"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_4_block_2_fc2_biasj5
features.4.block.3.0.weight

(
`

j6
features.5.block.0.0.weight


(

j6
features.5.block.1.0.weight




j˚
features.5.block.2.fc1.weight

@


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_5_block_2_fc1_weightjÍ
features.5.block.2.fc1.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_5_block_2_fc1_biasj˚
features.5.block.2.fc2.weight


@

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_5_block_2_fc2_weightjÎ
features.5.block.2.fc2.bias
	
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_5_block_2_fc2_biasj6
features.5.block.3.0.weight

(


j6
features.6.block.0.0.weight


(

j6
features.6.block.1.0.weight




j˚
features.6.block.2.fc1.weight

@


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_6_block_2_fc1_weightjÍ
features.6.block.2.fc1.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_6_block_2_fc1_biasj˚
features.6.block.2.fc2.weight


@

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_6_block_2_fc2_weightjÎ
features.6.block.2.fc2.bias
	
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_6_block_2_fc2_biasj6
features.6.block.3.0.weight

(


j5
features.7.block.0.0.weight

x
(

j5
features.7.block.1.0.weight

x


j˙
features.7.block.2.fc1.weight

 
x

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_7_block_2_fc1_weightjÍ
features.7.block.2.fc1.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_7_block_2_fc1_biasj˙
features.7.block.2.fc2.weight

x
 

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_7_block_2_fc2_weightjÍ
features.7.block.2.fc2.bias


x"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_7_block_2_fc2_biasj5
features.7.block.3.0.weight

0
x

j6
features.8.block.0.0.weight

ê
0

j6
features.8.block.1.0.weight

ê


j˚
features.8.block.2.fc1.weight

(
ê

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_8_block_2_fc1_weightjÍ
features.8.block.2.fc1.bias


("<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_8_block_2_fc1_biasj˚
features.8.block.2.fc2.weight

ê
(

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_8_block_2_fc2_weightjÎ
features.8.block.2.fc2.bias
	
ê"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_8_block_2_fc2_biasj6
features.8.block.3.0.weight

0
ê

j6
features.9.block.0.0.weight

†
0

j6
features.9.block.1.0.weight

†


j˚
features.9.block.2.fc1.weight

H
†

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_9_block_2_fc1_weightjÍ
features.9.block.2.fc1.bias


H"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_9_block_2_fc1_biasj˚
features.9.block.2.fc2.weight

†
H

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"D
!pkg.torch.onnx.original_node_namep_features_9_block_2_fc2_weightjÎ
features.9.block.2.fc2.bias
	
†"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"B
!pkg.torch.onnx.original_node_namep_features_9_block_2_fc2_biasj6
features.9.block.3.0.weight

`
†

j7
features.10.block.0.0.weight

¿
`

j7
features.10.block.1.0.weight

¿


j˛
features.10.block.2.fc1.weight

ê
¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_features_10_block_2_fc1_weightjÌ
features.10.block.2.fc1.bias
	
ê"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"C
!pkg.torch.onnx.original_node_namep_features_10_block_2_fc1_biasj˛
features.10.block.2.fc2.weight

¿
ê

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_features_10_block_2_fc2_weightjÌ
features.10.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"C
!pkg.torch.onnx.original_node_namep_features_10_block_2_fc2_biasj7
features.10.block.3.0.weight

`
¿

j7
features.11.block.0.0.weight

¿
`

j7
features.11.block.1.0.weight

¿


j˛
features.11.block.2.fc1.weight

ê
¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_features_11_block_2_fc1_weightjÌ
features.11.block.2.fc1.bias
	
ê"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"C
!pkg.torch.onnx.original_node_namep_features_11_block_2_fc1_biasj˛
features.11.block.2.fc2.weight

¿
ê

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_features_11_block_2_fc2_weightjÌ
features.11.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"C
!pkg.torch.onnx.original_node_namep_features_11_block_2_fc2_biasj7
features.11.block.3.0.weight

`
¿

j/
features.12.0.weight

¿
`

j‡
classifier.0.weight


Ä
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone":
!pkg.torch.onnx.original_node_namep_classifier_0_weightj◊
classifier.0.bias
	
Ä"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"8
!pkg.torch.onnx.original_node_namep_classifier_0_biasj‡
classifier.3.weight


Ä
Ä"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone":
!pkg.torch.onnx.original_node_namep_classifier_3_weightj◊
classifier.3.bias
	
Ä"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"8
!pkg.torch.onnx.original_node_namep_classifier_3_biasjR
val_23


"<
$pkg.onnxscript.optimizer.folded_from['val_21', 'val_22']jU
val_333


">
$pkg.onnxscript.optimizer.folded_from['val_331', 'val_332']j&
features.0.0.weight_bias


j.
 features.1.block.0.0.weight_bias


j.
 features.1.block.2.0.weight_bias


j.
 features.2.block.0.0.weight_bias


Hj.
 features.2.block.1.0.weight_bias


Hj.
 features.2.block.2.0.weight_bias


j.
 features.3.block.0.0.weight_bias


Xj.
 features.3.block.1.0.weight_bias


Xj.
 features.3.block.2.0.weight_bias


j.
 features.4.block.0.0.weight_bias


`j.
 features.4.block.1.0.weight_bias


`j.
 features.4.block.3.0.weight_bias


(j/
 features.5.block.0.0.weight_bias
	
j/
 features.5.block.1.0.weight_bias
	
j.
 features.5.block.3.0.weight_bias


(j/
 features.6.block.0.0.weight_bias
	
j/
 features.6.block.1.0.weight_bias
	
j.
 features.6.block.3.0.weight_bias


(j.
 features.7.block.0.0.weight_bias


xj.
 features.7.block.1.0.weight_bias


xj.
 features.7.block.3.0.weight_bias


0j/
 features.8.block.0.0.weight_bias
	
êj/
 features.8.block.1.0.weight_bias
	
êj.
 features.8.block.3.0.weight_bias


0j/
 features.9.block.0.0.weight_bias
	
†j/
 features.9.block.1.0.weight_bias
	
†j.
 features.9.block.3.0.weight_bias


`j0
!features.10.block.0.0.weight_bias
	
¿j0
!features.10.block.1.0.weight_bias
	
¿j/
!features.10.block.3.0.weight_bias


`j0
!features.11.block.0.0.weight_bias
	
¿j0
!features.11.block.1.0.weight_bias
	
¿j/
!features.11.block.3.0.weight_bias


`j(
features.12.0.weight_bias
	
¿j4
getitem)
'#


@
(((s0 - 1)//2)) + 1j6
	hardswish)
'#


@
(((s0 - 1)//2)) + 1j6
	getitem_3)
'#


 
(((s0 - 1)//4)) + 1j1
relu)
'#


 
(((s0 - 1)//4)) + 1j
mean




j"
conv2d_2




j 
relu_1




j"
conv2d_3




j%
hardsigmoid




j4
mul_369)
'#


 
(((s0 - 1)//4)) + 1j6
	getitem_6)
'#


 
(((s0 - 1)//4)) + 1j6
	getitem_9)
'#

H
 
(((s0 - 1)//4)) + 1j3
relu_2)
'#

H
 
(((s0 - 1)//4)) + 1j7

getitem_12)
'#

H

(((s0 - 1)//8)) + 1j3
relu_3)
'#

H

(((s0 - 1)//8)) + 1j7

getitem_15)
'#



(((s0 - 1)//8)) + 1j7

getitem_18)
'#

X

(((s0 - 1)//8)) + 1j3
relu_4)
'#

X

(((s0 - 1)//8)) + 1j7

getitem_21)
'#

X

(((s0 - 1)//8)) + 1j3
relu_5)
'#

X

(((s0 - 1)//8)) + 1j7

getitem_24)
'#



(((s0 - 1)//8)) + 1j4
add_503)
'#



(((s0 - 1)//8)) + 1j7

getitem_27)
'#

`

(((s0 - 1)//8)) + 1j8
hardswish_1)
'#

`

(((s0 - 1)//8)) + 1j8

getitem_30*
($

`

(((s0 - 1)//16)) + 1j9
hardswish_2*
($

`

(((s0 - 1)//16)) + 1j 
mean_1


`

j#
	conv2d_13




j 
relu_6




j#
	conv2d_14


`

j'
hardsigmoid_1


`

j5
mul_811*
($

`

(((s0 - 1)//16)) + 1j8

getitem_33*
($

(

(((s0 - 1)//16)) + 1j9

getitem_36+
)%



(((s0 - 1)//16)) + 1j:
hardswish_3+
)%



(((s0 - 1)//16)) + 1j9

getitem_39+
)%



(((s0 - 1)//16)) + 1j:
hardswish_4+
)%



(((s0 - 1)//16)) + 1j!
mean_2




j#
	conv2d_18


@

j 
relu_7


@

j$
	conv2d_19




j(
hardsigmoid_2




j7
mul_1125+
)%



(((s0 - 1)//16)) + 1j8

getitem_42*
($

(

(((s0 - 1)//16)) + 1j5
add_648*
($

(

(((s0 - 1)//16)) + 1j9

getitem_45+
)%



(((s0 - 1)//16)) + 1j:
hardswish_5+
)%



(((s0 - 1)//16)) + 1j9

getitem_48+
)%



(((s0 - 1)//16)) + 1j:
hardswish_6+
)%



(((s0 - 1)//16)) + 1j!
mean_3




j#
	conv2d_23


@

j 
relu_8


@

j$
	conv2d_24




j(
hardsigmoid_3




j7
mul_1451+
)%



(((s0 - 1)//16)) + 1j8

getitem_51*
($

(

(((s0 - 1)//16)) + 1j5
add_727*
($

(

(((s0 - 1)//16)) + 1j8

getitem_54*
($

x

(((s0 - 1)//16)) + 1j9
hardswish_7*
($

x

(((s0 - 1)//16)) + 1j8

getitem_57*
($

x

(((s0 - 1)//16)) + 1j9
hardswish_8*
($

x

(((s0 - 1)//16)) + 1j 
mean_4


x

j#
	conv2d_28


 

j 
relu_9


 

j#
	conv2d_29


x

j'
hardsigmoid_4


x

j6
mul_1777*
($

x

(((s0 - 1)//16)) + 1j8

getitem_60*
($

0

(((s0 - 1)//16)) + 1j9

getitem_63+
)%

ê

(((s0 - 1)//16)) + 1j:
hardswish_9+
)%

ê

(((s0 - 1)//16)) + 1j9

getitem_66+
)%

ê

(((s0 - 1)//16)) + 1j;
hardswish_10+
)%

ê

(((s0 - 1)//16)) + 1j!
mean_5


ê

j#
	conv2d_33


(

j!
relu_10


(

j$
	conv2d_34


ê

j(
hardsigmoid_5


ê

j7
mul_2091+
)%

ê

(((s0 - 1)//16)) + 1j8

getitem_69*
($

0

(((s0 - 1)//16)) + 1j5
add_872*
($

0

(((s0 - 1)//16)) + 1j9

getitem_72+
)%

†

(((s0 - 1)//16)) + 1j;
hardswish_11+
)%

†

(((s0 - 1)//16)) + 1j9

getitem_75+
)%

†

(((s0 - 1)//32)) + 1j;
hardswish_12+
)%

†

(((s0 - 1)//32)) + 1j!
mean_6


†

j#
	conv2d_38


H

j!
relu_11


H

j$
	conv2d_39


†

j(
hardsigmoid_6


†

j7
mul_2417+
)%

†

(((s0 - 1)//32)) + 1j8

getitem_78*
($

`

(((s0 - 1)//32)) + 1j9

getitem_81+
)%

¿

(((s0 - 1)//32)) + 1j;
hardswish_13+
)%

¿

(((s0 - 1)//32)) + 1j9

getitem_84+
)%

¿

(((s0 - 1)//32)) + 1j;
hardswish_14+
)%

¿

(((s0 - 1)//32)) + 1j!
mean_7


¿

j$
	conv2d_43


ê

j"
relu_12


ê

j$
	conv2d_44


¿

j(
hardsigmoid_7


¿

j7
mul_2731+
)%

¿

(((s0 - 1)//32)) + 1j8

getitem_87*
($

`

(((s0 - 1)//32)) + 1j6
add_1017*
($

`

(((s0 - 1)//32)) + 1j9

getitem_90+
)%

¿

(((s0 - 1)//32)) + 1j;
hardswish_15+
)%

¿

(((s0 - 1)//32)) + 1j9

getitem_93+
)%

¿

(((s0 - 1)//32)) + 1j;
hardswish_16+
)%

¿

(((s0 - 1)//32)) + 1j!
mean_8


¿

j$
	conv2d_48


ê

j"
relu_13


ê

j$
	conv2d_49


¿

j(
hardsigmoid_8


¿

j7
mul_3057+
)%

¿

(((s0 - 1)//32)) + 1j8

getitem_96*
($

`

(((s0 - 1)//32)) + 1j6
add_1096*
($

`

(((s0 - 1)//32)) + 1j9

getitem_99+
)%

¿

(((s0 - 1)//32)) + 1j;
hardswish_17+
)%

¿

(((s0 - 1)//32)) + 1j!
mean_9


¿

j
view
	

¿j
linear
	

Äj
hardswish_18
	

ÄÇÒ™
0pkg.torch.export.ExportedProgram.graph_signatureª™
# inputs
p_features_0_0_weight: PARAMETER target='features.0.0.weight'
p_features_0_1_weight: PARAMETER target='features.0.1.weight'
p_features_0_1_bias: PARAMETER target='features.0.1.bias'
p_features_1_block_0_0_weight: PARAMETER target='features.1.block.0.0.weight'
p_features_1_block_0_1_weight: PARAMETER target='features.1.block.0.1.weight'
p_features_1_block_0_1_bias: PARAMETER target='features.1.block.0.1.bias'
p_features_1_block_1_fc1_weight: PARAMETER target='features.1.block.1.fc1.weight'
p_features_1_block_1_fc1_bias: PARAMETER target='features.1.block.1.fc1.bias'
p_features_1_block_1_fc2_weight: PARAMETER target='features.1.block.1.fc2.weight'
p_features_1_block_1_fc2_bias: PARAMETER target='features.1.block.1.fc2.bias'
p_features_1_block_2_0_weight: PARAMETER target='features.1.block.2.0.weight'
p_features_1_block_2_1_weight: PARAMETER target='features.1.block.2.1.weight'
p_features_1_block_2_1_bias: PARAMETER target='features.1.block.2.1.bias'
p_features_2_block_0_0_weight: PARAMETER target='features.2.block.0.0.weight'
p_features_2_block_0_1_weight: PARAMETER target='features.2.block.0.1.weight'
p_features_2_block_0_1_bias: PARAMETER target='features.2.block.0.1.bias'
p_features_2_block_1_0_weight: PARAMETER target='features.2.block.1.0.weight'
p_features_2_block_1_1_weight: PARAMETER target='features.2.block.1.1.weight'
p_features_2_block_1_1_bias: PARAMETER target='features.2.block.1.1.bias'
p_features_2_block_2_0_weight: PARAMETER target='features.2.block.2.0.weight'
p_features_2_block_2_1_weight: PARAMETER target='features.2.block.2.1.weight'
p_features_2_block_2_1_bias: PARAMETER target='features.2.block.2.1.bias'
p_features_3_block_0_0_weight: PARAMETER target='features.3.block.0.0.weight'
p_features_3_block_0_1_weight: PARAMETER target='features.3.block.0.1.weight'
p_features_3_block_0_1_bias: PARAMETER target='features.3.block.0.1.bias'
p_features_3_block_1_0_weight: PARAMETER target='features.3.block.1.0.weight'
p_features_3_block_1_1_weight: PARAMETER target='features.3.block.1.1.weight'
p_features_3_block_1_1_bias: PARAMETER target='features.3.block.1.1.bias'
p_features_3_block_2_0_weight: PARAMETER target='features.3.block.2.0.weight'
p_features_3_block_2_1_weight: PARAMETER target='features.3.block.2.1.weight'
p_features_3_block_2_1_bias: PARAMETER target='features.3.block.2.1.bias'
p_features_4_block_0_0_weight: PARAMETER target='features.4.block.0.0.weight'
p_features_4_block_0_1_weight: PARAMETER target='features.4.block.0.1.weight'
p_features_4_block_0_1_bias: PARAMETER target='features.4.block.0.1.bias'
p_features_4_block_1_0_weight: PARAMETER target='features.4.block.1.0.weight'
p_features_4_block_1_1_weight: PARAMETER target='features.4.block.1.1.weight'
p_features_4_block_1_1_bias: PARAMETER target='features.4.block.1.1.bias'
p_features_4_block_2_fc1_weight: PARAMETER target='features.4.block.2.fc1.weight'
p_features_4_block_2_fc1_bias: PARAMETER target='features.4.block.2.fc1.bias'
p_features_4_block_2_fc2_weight: PARAMETER target='features.4.block.2.fc2.weight'
p_features_4_block_2_fc2_bias: PARAMETER target='features.4.block.2.fc2.bias'
p_features_4_block_3_0_weight: PARAMETER target='features.4.block.3.0.weight'
p_features_4_block_3_1_weight: PARAMETER target='features.4.block.3.1.weight'
p_features_4_block_3_1_bias: PARAMETER target='features.4.block.3.1.bias'
p_features_5_block_0_0_weight: PARAMETER target='features.5.block.0.0.weight'
p_features_5_block_0_1_weight: PARAMETER target='features.5.block.0.1.weight'
p_features_5_block_0_1_bias: PARAMETER target='features.5.block.0.1.bias'
p_features_5_block_1_0_weight: PARAMETER target='features.5.block.1.0.weight'
p_features_5_block_1_1_weight: PARAMETER target='features.5.block.1.1.weight'
p_features_5_block_1_1_bias: PARAMETER target='features.5.block.1.1.bias'
p_features_5_block_2_fc1_weight: PARAMETER target='features.5.block.2.fc1.weight'
p_features_5_block_2_fc1_bias: PARAMETER target='features.5.block.2.fc1.bias'
p_features_5_block_2_fc2_weight: PARAMETER target='features.5.block.2.fc2.weight'
p_features_5_block_2_fc2_bias: PARAMETER target='features.5.block.2.fc2.bias'
p_features_5_block_3_0_weight: PARAMETER target='features.5.block.3.0.weight'
p_features_5_block_3_1_weight: PARAMETER target='features.5.block.3.1.weight'
p_features_5_block_3_1_bias: PARAMETER target='features.5.block.3.1.bias'
p_features_6_block_0_0_weight: PARAMETER target='features.6.block.0.0.weight'
p_features_6_block_0_1_weight: PARAMETER target='features.6.block.0.1.weight'
p_features_6_block_0_1_bias: PARAMETER target='features.6.block.0.1.bias'
p_features_6_block_1_0_weight: PARAMETER target='features.6.block.1.0.weight'
p_features_6_block_1_1_weight: PARAMETER target='features.6.block.1.1.weight'
p_features_6_block_1_1_bias: PARAMETER target='features.6.block.1.1.bias'
p_features_6_block_2_fc1_weight: PARAMETER target='features.6.block.2.fc1.weight'
p_features_6_block_2_fc1_bias: PARAMETER target='features.6.block.2.fc1.bias'
p_features_6_block_2_fc2_weight: PARAMETER target='features.6.block.2.fc2.weight'
p_features_6_block_2_fc2_bias: PARAMETER target='features.6.block.2.fc2.bias'
p_features_6_block_3_0_weight: PARAMETER target='features.6.block.3.0.weight'
p_features_6_block_3_1_weight: PARAMETER target='features.6.block.3.1.weight'
p_features_6_block_3_1_bias: PARAMETER target='features.6.block.3.1.bias'
p_features_7_block_0_0_weight: PARAMETER target='features.7.block.0.0.weight'
p_features_7_block_0_1_weight: PARAMETER target='features.7.block.0.1.weight'
p_features_7_block_0_1_bias: PARAMETER target='features.7.block.0.1.bias'
p_features_7_block_1_0_weight: PARAMETER target='features.7.block.1.0.weight'
p_features_7_block_1_1_weight: PARAMETER target='features.7.block.1.1.weight'
p_features_7_block_1_1_bias: PARAMETER target='features.7.block.1.1.bias'
p_features_7_block_2_fc1_weight: PARAMETER target='features.7.block.2.fc1.weight'
p_features_7_block_2_fc1_bias: PARAMETER target='features.7.block.2.fc1.bias'
p_features_7_block_2_fc2_weight: PARAMETER target='features.7.block.2.fc2.weight'
p_features_7_block_2_fc2_bias: PARAMETER target='features.7.block.2.fc2.bias'
p_features_7_block_3_0_weight: PARAMETER target='features.7.block.3.0.weight'
p_features_7_block_3_1_weight: PARAMETER target='features.7.block.3.1.weight'
p_features_7_block_3_1_bias: PARAMETER target='features.7.block.3.1.bias'
p_features_8_block_0_0_weight: PARAMETER target='features.8.block.0.0.weight'
p_features_8_block_0_1_weight: PARAMETER target='features.8.block.0.1.weight'
p_features_8_block_0_1_bias: PARAMETER target='features.8.block.0.1.bias'
p_features_8_block_1_0_weight: PARAMETER target='features.8.block.1.0.weight'
p_features_8_block_1_1_weight: PARAMETER target='features.8.block.1.1.weight'
p_features_8_block_1_1_bias: PARAMETER target='features.8.block.1.1.bias'
p_features_8_block_2_fc1_weight: PARAMETER target='features.8.block.2.fc1.weight'
p_features_8_block_2_fc1_bias: PARAMETER target='features.8.block.2.fc1.bias'
p_features_8_block_2_fc2_weight: PARAMETER target='features.8.block.2.fc2.weight'
p_features_8_block_2_fc2_bias: PARAMETER target='features.8.block.2.fc2.bias'
p_features_8_block_3_0_weight: PARAMETER target='features.8.block.3.0.weight'
p_features_8_block_3_1_weight: PARAMETER target='features.8.block.3.1.weight'
p_features_8_block_3_1_bias: PARAMETER target='features.8.block.3.1.bias'
p_features_9_block_0_0_weight: PARAMETER target='features.9.block.0.0.weight'
p_features_9_block_0_1_weight: PARAMETER target='features.9.block.0.1.weight'
p_features_9_block_0_1_bias: PARAMETER target='features.9.block.0.1.bias'
p_features_9_block_1_0_weight: PARAMETER target='features.9.block.1.0.weight'
p_features_9_block_1_1_weight: PARAMETER target='features.9.block.1.1.weight'
p_features_9_block_1_1_bias: PARAMETER target='features.9.block.1.1.bias'
p_features_9_block_2_fc1_weight: PARAMETER target='features.9.block.2.fc1.weight'
p_features_9_block_2_fc1_bias: PARAMETER target='features.9.block.2.fc1.bias'
p_features_9_block_2_fc2_weight: PARAMETER target='features.9.block.2.fc2.weight'
p_features_9_block_2_fc2_bias: PARAMETER target='features.9.block.2.fc2.bias'
p_features_9_block_3_0_weight: PARAMETER target='features.9.block.3.0.weight'
p_features_9_block_3_1_weight: PARAMETER target='features.9.block.3.1.weight'
p_features_9_block_3_1_bias: PARAMETER target='features.9.block.3.1.bias'
p_features_10_block_0_0_weight: PARAMETER target='features.10.block.0.0.weight'
p_features_10_block_0_1_weight: PARAMETER target='features.10.block.0.1.weight'
p_features_10_block_0_1_bias: PARAMETER target='features.10.block.0.1.bias'
p_features_10_block_1_0_weight: PARAMETER target='features.10.block.1.0.weight'
p_features_10_block_1_1_weight: PARAMETER target='features.10.block.1.1.weight'
p_features_10_block_1_1_bias: PARAMETER target='features.10.block.1.1.bias'
p_features_10_block_2_fc1_weight: PARAMETER target='features.10.block.2.fc1.weight'
p_features_10_block_2_fc1_bias: PARAMETER target='features.10.block.2.fc1.bias'
p_features_10_block_2_fc2_weight: PARAMETER target='features.10.block.2.fc2.weight'
p_features_10_block_2_fc2_bias: PARAMETER target='features.10.block.2.fc2.bias'
p_features_10_block_3_0_weight: PARAMETER target='features.10.block.3.0.weight'
p_features_10_block_3_1_weight: PARAMETER target='features.10.block.3.1.weight'
p_features_10_block_3_1_bias: PARAMETER target='features.10.block.3.1.bias'
p_features_11_block_0_0_weight: PARAMETER target='features.11.block.0.0.weight'
p_features_11_block_0_1_weight: PARAMETER target='features.11.block.0.1.weight'
p_features_11_block_0_1_bias: PARAMETER target='features.11.block.0.1.bias'
p_features_11_block_1_0_weight: PARAMETER target='features.11.block.1.0.weight'
p_features_11_block_1_1_weight: PARAMETER target='features.11.block.1.1.weight'
p_features_11_block_1_1_bias: PARAMETER target='features.11.block.1.1.bias'
p_features_11_block_2_fc1_weight: PARAMETER target='features.11.block.2.fc1.weight'
p_features_11_block_2_fc1_bias: PARAMETER target='features.11.block.2.fc1.bias'
p_features_11_block_2_fc2_weight: PARAMETER target='features.11.block.2.fc2.weight'
p_features_11_block_2_fc2_bias: PARAMETER target='features.11.block.2.fc2.bias'
p_features_11_block_3_0_weight: PARAMETER target='features.11.block.3.0.weight'
p_features_11_block_3_1_weight: PARAMETER target='features.11.block.3.1.weight'
p_features_11_block_3_1_bias: PARAMETER target='features.11.block.3.1.bias'
p_features_12_0_weight: PARAMETER target='features.12.0.weight'
p_features_12_1_weight: PARAMETER target='features.12.1.weight'
p_features_12_1_bias: PARAMETER target='features.12.1.bias'
p_classifier_0_weight: PARAMETER target='classifier.0.weight'
p_classifier_0_bias: PARAMETER target='classifier.0.bias'
p_classifier_3_weight: PARAMETER target='classifier.3.weight'
p_classifier_3_bias: PARAMETER target='classifier.3.bias'
b_features_0_1_running_mean: BUFFER target='features.0.1.running_mean' persistent=True
b_features_0_1_running_var: BUFFER target='features.0.1.running_var' persistent=True
b_features_0_1_num_batches_tracked: BUFFER target='features.0.1.num_batches_tracked' persistent=True
b_features_1_block_0_1_running_mean: BUFFER target='features.1.block.0.1.running_mean' persistent=True
b_features_1_block_0_1_running_var: BUFFER target='features.1.block.0.1.running_var' persistent=True
b_features_1_block_0_1_num_batches_tracked: BUFFER target='features.1.block.0.1.num_batches_tracked' persistent=True
b_features_1_block_2_1_running_mean: BUFFER target='features.1.block.2.1.running_mean' persistent=True
b_features_1_block_2_1_running_var: BUFFER target='features.1.block.2.1.running_var' persistent=True
b_features_1_block_2_1_num_batches_tracked: BUFFER target='features.1.block.2.1.num_batches_tracked' persistent=True
b_features_2_block_0_1_running_mean: BUFFER target='features.2.block.0.1.running_mean' persistent=True
b_features_2_block_0_1_running_var: BUFFER target='features.2.block.0.1.running_var' persistent=True
b_features_2_block_0_1_num_batches_tracked: BUFFER target='features.2.block.0.1.num_batches_tracked' persistent=True
b_features_2_block_1_1_running_mean: BUFFER target='features.2.block.1.1.running_mean' persistent=True
b_features_2_block_1_1_running_var: BUFFER target='features.2.block.1.1.running_var' persistent=True
b_features_2_block_1_1_num_batches_tracked: BUFFER target='features.2.block.1.1.num_batches_tracked' persistent=True
b_features_2_block_2_1_running_mean: BUFFER target='features.2.block.2.1.running_mean' persistent=True
b_features_2_block_2_1_running_var: BUFFER target='features.2.block.2.1.running_var' persistent=True
b_features_2_block_2_1_num_batches_tracked: BUFFER target='features.2.block.2.1.num_batches_tracked' persistent=True
b_features_3_block_0_1_running_mean: BUFFER target='features.3.block.0.1.running_mean' persistent=True
b_features_3_block_0_1_running_var: BUFFER target='features.3.block.0.1.running_var' persistent=True
b_features_3_block_0_1_num_batches_tracked: BUFFER target='features.3.block.0.1.num_batches_tracked' persistent=True
b_features_3_block_1_1_running_mean: BUFFER target='features.3.block.1.1.running_mean' persistent=True
b_features_3_block_1_1_running_var: BUFFER target='features.3.block.1.1.running_var' persistent=True
b_features_3_block_1_1_num_batches_tracked: BUFFER target='features.3.block.1.1.num_batches_tracked' persistent=True
b_features_3_block_2_1_running_mean: BUFFER target='features.3.block.2.1.running_mean' persistent=True
b_features_3_block_2_1_running_var: BUFFER target='features.3.block.2.1.running_var' persistent=True
b_features_3_block_2_1_num_batches_tracked: BUFFER target='features.3.block.2.1.num_batches_tracked' persistent=True
b_features_4_block_0_1_running_mean: BUFFER target='features.4.block.0.1.running_mean' persistent=True
b_features_4_block_0_1_running_var: BUFFER target='features.4.block.0.1.running_var' persistent=True
b_features_4_block_0_1_num_batches_tracked: BUFFER target='features.4.block.0.1.num_batches_tracked' persistent=True
b_features_4_block_1_1_running_mean: BUFFER target='features.4.block.1.1.running_mean' persistent=True
b_features_4_block_1_1_running_var: BUFFER target='features.4.block.1.1.running_var' persistent=True
b_features_4_block_1_1_num_batches_tracked: BUFFER target='features.4.block.1.1.num_batches_tracked' persistent=True
b_features_4_block_3_1_running_mean: BUFFER target='features.4.block.3.1.running_mean' persistent=True
b_features_4_block_3_1_running_var: BUFFER target='features.4.block.3.1.running_var' persistent=True
b_features_4_block_3_1_num_batches_tracked: BUFFER target='features.4.block.3.1.num_batches_tracked' persistent=True
b_features_5_block_0_1_running_mean: BUFFER target='features.5.block.0.1.running_mean' persistent=True
b_features_5_block_0_1_running_var: BUFFER target='features.5.block.0.1.running_var' persistent=True
b_features_5_block_0_1_num_batches_tracked: BUFFER target='features.5.block.0.1.num_batches_tracked' persistent=True
b_features_5_block_1_1_running_mean: BUFFER target='features.5.block.1.1.running_mean' persistent=True
b_features_5_block_1_1_running_var: BUFFER target='features.5.block.1.1.running_var' persistent=True
b_features_5_block_1_1_num_batches_tracked: BUFFER target='features.5.block.1.1.num_batches_tracked' persistent=True
b_features_5_block_3_1_running_mean: BUFFER target='features.5.block.3.1.running_mean' persistent=True
b_features_5_block_3_1_running_var: BUFFER target='features.5.block.3.1.running_var' persistent=True
b_features_5_block_3_1_num_batches_tracked: BUFFER target='features.5.block.3.1.num_batches_tracked' persistent=True
b_features_6_block_0_1_running_mean: BUFFER target='features.6.block.0.1.running_mean' persistent=True
b_features_6_block_0_1_running_var: BUFFER target='features.6.block.0.1.running_var' persistent=True
b_features_6_block_0_1_num_batches_tracked: BUFFER target='features.6.block.0.1.num_batches_tracked' persistent=True
b_features_6_block_1_1_running_mean: BUFFER target='features.6.block.1.1.running_mean' persistent=True
b_features_6_block_1_1_running_var: BUFFER target='features.6.block.1.1.running_var' persistent=True
b_features_6_block_1_1_num_batches_tracked: BUFFER target='features.6.block.1.1.num_batches_tracked' persistent=True
b_features_6_block_3_1_running_mean: BUFFER target='features.6.block.3.1.running_mean' persistent=True
b_features_6_block_3_1_running_var: BUFFER target='features.6.block.3.1.running_var' persistent=True
b_features_6_block_3_1_num_batches_tracked: BUFFER target='features.6.block.3.1.num_batches_tracked' persistent=True
b_features_7_block_0_1_running_mean: BUFFER target='features.7.block.0.1.running_mean' persistent=True
b_features_7_block_0_1_running_var: BUFFER target='features.7.block.0.1.running_var' persistent=True
b_features_7_block_0_1_num_batches_tracked: BUFFER target='features.7.block.0.1.num_batches_tracked' persistent=True
b_features_7_block_1_1_running_mean: BUFFER target='features.7.block.1.1.running_mean' persistent=True
b_features_7_block_1_1_running_var: BUFFER target='features.7.block.1.1.running_var' persistent=True
b_features_7_block_1_1_num_batches_tracked: BUFFER target='features.7.block.1.1.num_batches_tracked' persistent=True
b_features_7_block_3_1_running_mean: BUFFER target='features.7.block.3.1.running_mean' persistent=True
b_features_7_block_3_1_running_var: BUFFER target='features.7.block.3.1.running_var' persistent=True
b_features_7_block_3_1_num_batches_tracked: BUFFER target='features.7.block.3.1.num_batches_tracked' persistent=True
b_features_8_block_0_1_running_mean: BUFFER target='features.8.block.0.1.running_mean' persistent=True
b_features_8_block_0_1_running_var: BUFFER target='features.8.block.0.1.running_var' persistent=True
b_features_8_block_0_1_num_batches_tracked: BUFFER target='features.8.block.0.1.num_batches_tracked' persistent=True
b_features_8_block_1_1_running_mean: BUFFER target='features.8.block.1.1.running_mean' persistent=True
b_features_8_block_1_1_running_var: BUFFER target='features.8.block.1.1.running_var' persistent=True
b_features_8_block_1_1_num_batches_tracked: BUFFER target='features.8.block.1.1.num_batches_tracked' persistent=True
b_features_8_block_3_1_running_mean: BUFFER target='features.8.block.3.1.running_mean' persistent=True
b_features_8_block_3_1_running_var: BUFFER target='features.8.block.3.1.running_var' persistent=True
b_features_8_block_3_1_num_batches_tracked: BUFFER target='features.8.block.3.1.num_batches_tracked' persistent=True
b_features_9_block_0_1_running_mean: BUFFER target='features.9.block.0.1.running_mean' persistent=True
b_features_9_block_0_1_running_var: BUFFER target='features.9.block.0.1.running_var' persistent=True
b_features_9_block_0_1_num_batches_tracked: BUFFER target='features.9.block.0.1.num_batches_tracked' persistent=True
b_features_9_block_1_1_running_mean: BUFFER target='features.9.block.1.1.running_mean' persistent=True
b_features_9_block_1_1_running_var: BUFFER target='features.9.block.1.1.running_var' persistent=True
b_features_9_block_1_1_num_batches_tracked: BUFFER target='features.9.block.1.1.num_batches_tracked' persistent=True
b_features_9_block_3_1_running_mean: BUFFER target='features.9.block.3.1.running_mean' persistent=True
b_features_9_block_3_1_running_var: BUFFER target='features.9.block.3.1.running_var' persistent=True
b_features_9_block_3_1_num_batches_tracked: BUFFER target='features.9.block.3.1.num_batches_tracked' persistent=True
b_features_10_block_0_1_running_mean: BUFFER target='features.10.block.0.1.running_mean' persistent=True
b_features_10_block_0_1_running_var: BUFFER target='features.10.block.0.1.running_var' persistent=True
b_features_10_block_0_1_num_batches_tracked: BUFFER target='features.10.block.0.1.num_batches_tracked' persistent=True
b_features_10_block_1_1_running_mean: BUFFER target='features.10.block.1.1.running_mean' persistent=True
b_features_10_block_1_1_running_var: BUFFER target='features.10.block.1.1.running_var' persistent=True
b_features_10_block_1_1_num_batches_tracked: BUFFER target='features.10.block.1.1.num_batches_tracked' persistent=True
b_features_10_block_3_1_running_mean: BUFFER target='features.10.block.3.1.running_mean' persistent=True
b_features_10_block_3_1_running_var: BUFFER target='features.10.block.3.1.running_var' persistent=True
b_features_10_block_3_1_num_batches_tracked: BUFFER target='features.10.block.3.1.num_batches_tracked' persistent=True
b_features_11_block_0_1_running_mean: BUFFER target='features.11.block.0.1.running_mean' persistent=True
b_features_11_block_0_1_running_var: BUFFER target='features.11.block.0.1.running_var' persistent=True
b_features_11_block_0_1_num_batches_tracked: BUFFER target='features.11.block.0.1.num_batches_tracked' persistent=True
b_features_11_block_1_1_running_mean: BUFFER target='features.11.block.1.1.running_mean' persistent=True
b_features_11_block_1_1_running_var: BUFFER target='features.11.block.1.1.running_var' persistent=True
b_features_11_block_1_1_num_batches_tracked: BUFFER target='features.11.block.1.1.num_batches_tracked' persistent=True
b_features_11_block_3_1_running_mean: BUFFER target='features.11.block.3.1.running_mean' persistent=True
b_features_11_block_3_1_running_var: BUFFER target='features.11.block.3.1.running_var' persistent=True
b_features_11_block_3_1_num_batches_tracked: BUFFER target='features.11.block.3.1.num_batches_tracked' persistent=True
b_features_12_1_running_mean: BUFFER target='features.12.1.running_mean' persistent=True
b_features_12_1_running_var: BUFFER target='features.12.1.running_var' persistent=True
b_features_12_1_num_batches_tracked: BUFFER target='features.12.1.num_batches_tracked' persistent=True
x: USER_INPUT

# outputs
linear_1: USER_OUTPUT
Ç\
2pkg.torch.export.ExportedProgram.range_constraints&{s77: VR[0, 65535], s0: VR[0, int_oo]}B
 