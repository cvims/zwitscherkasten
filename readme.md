<p align="center">
  <samp>ğ—­ğ—ªğ—œğ—§ğ—¦ğ—–ğ—›ğ—˜ğ—¥ğ—ğ—”ğ—¦ğ—§ğ—˜ğ—¡</samp><br><br>
  <img src="monitoring.png" alt="Zwitscherkasten logo" width="500"/><br><br>
  <b>A multimodal bird monitoring system combining audio & vision intelligence for edge deployment</b><br><br>
  ğŸ“„ <i>Find our paper on arXiv <a href="https://arxiv.org/abs/2602.13330">here</a></i> â€¢ 
  ğŸ’¾ <i>Pre-trained models on <a href="https://zenodo.org/records/18499119">Zenodo</a></i>
</p>


---

## âœ¨ Features

ğŸ™ï¸ **Audio Classification** â€“ EfficientNet, MobileNet, PaSST models for species recognition

ğŸ‘ï¸ **Vision Classification** â€“ YOLO-based image detection and classification

ğŸ“± **iOS App** â€“ Native iOS application with on-device inference

ğŸŒ **Web Interface** â€“ Real-time inference dashboard

âš¡ **Edge Optimized** â€“ Designed for Raspberry Pi, Rubik Pi, and compatible hardware

---

## ğŸ—ï¸ Architecture

```
â”œâ”€â”€ Audio_Classification/      AI models for audio-based bird recognition
â”œâ”€â”€ Vision_Classification/     YOLO models for image-based detection
â”œâ”€â”€ Audio_Intent/              Intent recognition for user interactions
â”œâ”€â”€ IOS_App/                   Native iOS application
â”œâ”€â”€ WebApp/                    Web-based inference interface
â””â”€â”€ Rubik/                     Edge device integration & streaming
```

## Citation
If you use Zwitscherkasten in your research or project, please cite our paper:
```
@misc{blum2026zwitscherkastendiyaudiovisual,
      title={Zwitscherkasten -- DIY Audiovisual bird monitoring}, 
      author={Dominik Blum and Elias HÃ¤ring and Fabian Jirges and Martin SchÃ¤ffer and David Schick and Florian Schulenberg and Torsten SchÃ¶n},
      year={2026},
      eprint={2602.13330},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2602.13330}, 
}
```





â€‹